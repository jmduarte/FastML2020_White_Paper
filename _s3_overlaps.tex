\noindent 
\textcolor{blue}{
The focus of these sections is to source material from Sec.~\ref{sec:apps} and lay out similarities and differences.
}
Real-time/accelerated AI inference show promises in improving the discovery potential at current and planned scientific instruments across the domains as detailed in Sec.~\ref{sec:apps}. Design of high performant specialty systems for real-time/accelerated AI applications requires particular attention to the figure-of-merit of the target domain's ML algorithm. It might be dominated by its latency per inference, computational cost (e.g., power consumption), reliability, security, and ability to operate in extreme environments (e.g., radiation). For instance, ML might need to: trigger acquisition systems for rare events with ~100 ns latency on the Large Hadron Collider~\cite{Duarte:2018ite}; analyze multi-channel ambulatory health monitors at kHz frequencies where wireless transfer of data is not possible due to power limitations (\char`\~50 iPhone batteries/day for data transfer) or security requirements; or to keep pace with materials spectroscopy data streams on the order of Tb/s~\cite{Hart2017-bf}. Furthermore, real-time-analysis of advanced scientific instrumentation must have uninterrupted allocation of computing resources and patient sensitive information processed by wireless health devices must be secured. Such features and characteristics create quantifiable guidelines for understanding distinctions and commonalities among domains and applications. Thereby, we can coordinate efforts towards creating fundamental design principles and tools, which may address needs across seemingly disparate domains. Appropriate data representation is an essential first step of the design process as it determines the choice of NN architecture to be implemented in real time systems that need to meet the performance targets outlined above. Prominent data representations of different scientific instruments are summarized below. Other areas of overlap across domains such as NN and hardware co-design tools and workflows, NN complexity reduction with quantization and pruning are also recent technology advancements in real-time/accelerated AI and therefore are outlined in ~\ref{sec:technolog_sota}.
\subsection{Data representations}
Data representation used in a particular domain influences both the computation system to process the data as well as the requirements for storage. One global classification for data representations across domains can be considered as being into raw versus reconstructed data. The data representation often varies depending on the stage of the reconstruction and the upstream steps in the data processing pipeline. Existing applications include fully connected NNs that often take pre-processed expert feature variables as inputs or CNNs when the data is of image nature. On-going development of domain knowledge inspired NN algorithms could further take advantage of the expert features in the accuracy and efficiency as detailed below.
To fully exploit the power of advanced NNs and bring it closer to data creation for minimum information loss, more suitable representation of the raw data, e.g as point clouds, needs to be employed. Prominent representations for raw data from different experimental and measurement systems are:
    \begin{itemize}
        \item \textbf{Spatial Data}: Used for describing physical objects in geometric space. There are two main types, called vector and raster data. Vector data, in turn, can be comprised of points, lines, or polygons. Raster data refers to a grid of pixels, such as images, but pixels can also represent other measurements such as intensity, charge, field strength, etc.
        \item \textbf{Point Clouds}: Can be considered a type of spatial data. This data representation is created by collating a set of spatial data, i.e., points in a 3D space, that usually form an object in space collectively. 
        \item \textbf{Temporal Data}: Used to represent the state of a system/experiment at a particular time. Data collected across time, in a specific order, is classified in this manner. Time-series data is a subset of this representation, where data is sampled at regular time intervals.
        \item \textbf{Spatio-Temporal Data}: Measurements and observations of a system can be collected across both the space and time dimensions. In that case, the data can be considered as spatio-temporal. 
        \item \textbf{Multispectral Data}: Used to represent outputs of multiple sensors that capture measurements from multiple bands of the electromagnetic spectrum. Multispectral representation is commonly used in the context of imaging, involving sensors that are sensitive to different wavelengths of light. This usually involves in the order of few to 10s of spectra.    
        \item \textbf{Hyperspectral Data}: Used to represent measurements from a high number of spectra, e.g., in the order of 100s. These images collected from different narrow band spectra are combined into a so called hyperspectral cube with three main dimensions. The first two reference the 2D spatial placement (e.g., earths surface) while the third dimension represents the complete spectrum content at each ``pixel'' location.  
    \end{itemize} .  
  Cost of data communication (in terms of latency) and data storage (in terms of the cost of acquiring and managing the physical storage resources) present important challenges. Particularly, application domains, which require real-time analysis and/or real-time feedback demand highly optimized data analytics solutions. Applications that rely on hyper-spectral data are faced with an ever increasing rate of data input across the electromagnetic spectrum. High-speed data reduction is required in these domains. Applications that generate large scale point clouds similarly demand efficient compression on their spatial data. Application domains that handle multi-spectral data with limited spatial resolution require ultra-fast reconstruction in order to enable real-time control feedback. Another challenge is posed by applications that rely on accurate analysis of streaming time-series data, yet they are forced to perform under highly limited storage and communication resources, either due to privacy and security concerns or limitations of the associated edge devices.  

    Some current efforts in developing ML solutions to data processing front-ends focus on developing autoencoder based compression engines~\cite{}. ML-based dimensionality reduction for hyper-spectral data is another direction, which has drawn attention~\cite{}. Deep learning-based approaches are investigated for image reconstruction; the field of materal sciences being one of the most active fields in that regards~\cite{Schmidt_nature2019}. 

\subsubsection{Expert Feature DNNs}

\begin{itemize}
    \item \textbf{Context}: While ML has provided many approaches to attain high-level data representations through mathematical transformations, a preferred approach uses Deep Neural Networks DNNs~\cite{Goodfellow_2016}. In DNNs, layers of neurons above the original input signal are built to ensure that each new layer captures a more abstract representation of the data. Each layer constructs new features by forming nonlinear combinations of the features in the layer below. This hierarchical approach to feature construction has been effective in disentangling factors of variation in the data~\cite{Hinton_2006,Bengio_2013,Goodfellow_2016}, and has been useful to construct informative and meaningful representations. In astronomical images, for example, a DNN starts with low-level pixel information, gradually capturing at upper layers edges, motifs, and eventually entire objects (e.g., galaxies), to provide a broad view of the Universe~\cite{Sanchez_2018,Huertas_Company_2018}. The same applies to other fields of science. For example, detecting particles in large accelerators requires transforming low-level signals into dynamic patterns that can be ascribed to specific particles~\cite{Belayneh_2020}. In medical imaging, there is a need to quickly identify anomalous tissue from low-level pixel information by gradually capturing global tissue patterns~\cite{Bychkov_2018}. The importance of transforming the initial input data into meaningful abstract representations cannot be overstated; it remains one of the most powerful properties of modern neural network architectures. 
    \item \textbf{Challenges}: Several challenges exist in the construction of increasingly abstract representations using DNNs. One challenge is to incorporate domain knowledge (e.g., physical constraints) into the neural network model. This is not only important to address the need for excessively large amounts of data when training a DNN, but also to narrow the gap in representational bias between the model and target concept. Under scarce data but abundant domain expertise, adding domain knowledge can expedite the training process~\cite{Xie_2021} as well as a more computionally efficient interference. Another challenge is to develop tools for model interpretability by explaining the semantics of the representations embedded at each layer~\cite{Chakraborty_2017}. This is challenging due to the distributed representation of information in the network architecture. 
    \item \textbf{Existing and future work in ML}: Despite the lack of a formal mechanism to attain a seamless integration between a statistical model and domain knowledge, current approaches point to interesting directions, e.g., using knowledge to add training data or to change the loss function~\cite{Vo_2017}. Model interpretability in DNNs has seen an upsurge in research over the past years~\cite{Chakraborty_2017}. Commonly, studies look at individual units and their activation patterns to elucidate what is learned across layers of neurons. 
\end{itemize}
\subsubsection{Frame-based images}
Domains: neutrino detection, 
\subsubsection{Point clouds}
 Point cloud data representation is often used in HEP, where multiple frames of event-based measurements collected by a large number of detectors are combined into a data set. Across many HEP applications point clouds commonly help to represent particle jets with data sizes exceeding Pb/s. More broadly, point clouds can be used to capture any 3D space-event and interactions of moving parts in space. Various types of scan-based imaging data can be represented as point clouds. Other domains such as CT and PET scanning in biomedical engineering and virtual reality also utilize this representation for imaging. 3D scanners used for product design, solid object modeling, architecture, and infrastructure design leverage point clouds as well. Many of these imaging tasks generate point clouds of sizes in the order of several GB to TB. Domains sharing point cloud representation (e.g., HEP and biomedical imaging) also commonly involve spatial characteristics. 
 \subsubsection{Multi-/Hyperspectral Data}
 Multispectral data is common between wireless health monitoring and wireless communication systems. A set of physiological sensors, often representing different modalities, are combined into a multispectral data set for health monitoring and intervention systems. For wireless communication, signal interference and network traffic conditions are captured via multispectral data. Both domains capture this data across the time domain, so also exhibit temporal features. Furthermore, in both domains generated data size can be considered relatively smaller (ranging from 100s of Mb/s to 10s of Gb/s), compared to the rest of the domains discussed in this article. Hyperspectral data is used across many astronomy applications, medical imaging, and electron microscopy, which is used to drive many materials science design and discovery applications. Emerging multimessenger astronomy applications further emphasize the utility of hyperspectral data representations combining observations from a wide array of detectors and telescopes. 
\subsubsection{Time-series data}

\subsection{System constraints}
In this section we present an overview of system constraints that are prevalent across a number of application domains. At the same time, there are unique challenges arising from specific choices of implementation platforms.


\begin{tabular}{ c c c c c }
 Domain &  Data & Latency & Form Factor &  Energy \\
 cell1  & cell2 & cell3   & cell1       & cell2  \\ 
 cell4 & cell5 & cell6 & cell1 & cell2  \\  
 cell7 & cell8 & cell9 & cell1 & cell2    
\end{tabular}



\subsubsection{Hard real-time embedded systems}
\subsubsection{Soft real-time coprocessors}