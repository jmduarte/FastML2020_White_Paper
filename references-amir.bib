
@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@inproceedings{hauser2001approximating,
  title={Approximating functions for embedded and ASIC applications},
  author={Hauser, James W and Purdy, Carla N},
  booktitle={Proceedings of the 44th IEEE 2001 Midwest Symposium on Circuits and Systems. MWSCAS 2001 (Cat. No. 01CH37257)},
  volume={1},
  pages={478--481},
  year={2001},
  organization={IEEE}
}
@article{lin2015neural,
  title={Neural networks with few multiplications},
  author={Lin, Zhouhan and Courbariaux, Matthieu and Memisevic, Roland and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1510.03009},
  year={2015}
}
@article{zhou2017adaptive,
  title={Adaptive quantization for deep neural network},
  author={Zhou, Yiren and Moosavi-Dezfooli, Seyed-Mohsen and Cheung, Ngai-Man and Frossard, Pascal},
  journal={arXiv preprint arXiv:1712.01048},
  year={2017}
}

@article{zhu2016trained,
  title={Trained ternary quantization},
  author={Zhu, Chenzhuo and Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1612.01064},
  year={2016}
}
@article{sun2019patient,
  title={Patient knowledge distillation for bert model compression},
  author={Sun, Siqi and Cheng, Yu and Gan, Zhe and Liu, Jingjing},
  journal={arXiv preprint arXiv:1908.09355},
  year={2019}
}

@article{jiao2019tinybert,
  title={Tinybert: Distilling bert for natural language understanding},
  author={Jiao, Xiaoqi and Yin, Yichun and Shang, Lifeng and Jiang, Xin and Chen, Xiao and Li, Linlin and Wang, Fang and Liu, Qun},
  journal={arXiv preprint arXiv:1909.10351},
  year={2019}
}


@article{tang2019distilling,
  title={Distilling task-specific knowledge from bert into simple neural networks},
  author={Tang, Raphael and Lu, Yao and Liu, Linqing and Mou, Lili and Vechtomova, Olga and Lin, Jimmy},
  journal={arXiv preprint arXiv:1903.12136},
  year={2019}
}
@article{blalock2020state,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
  journal={arXiv preprint arXiv:2003.03033},
  year={2020}
}
@misc{hawks2021ps,
      title={Ps and Qs: Quantization-aware pruning for efficient low latency neural network inference}, 
      author={Benjamin Hawks and Javier Duarte and Nicholas J. Fraser and Alessandro Pappalardo and Nhan Tran and Yaman Umuroglu},
      year={2021},
      eprint={2102.11289},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{hoefler2021sparsity,
  title={Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks},
  author={Hoefler, Torsten and Alistarh, Dan and Ben-Nun, Tal and Dryden, Nikoli and Peste, Alexandra},
  journal={arXiv preprint arXiv:2102.00554},
  year={2021}
}
@inproceedings{lin2016fixed,
  title={Fixed point quantization of deep convolutional networks},
  author={Lin, Darryl and Talathi, Sachin and Annapureddy, Sreekanth},
  booktitle={International conference on machine learning},
  pages={2849--2858},
  year={2016},
  organization={PMLR}
}
@article{turc2019well,
  title={Well-read students learn better: On the importance of pre-training compact models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962},
  year={2019}
}



@article{hou2016loss,
  title={Loss-aware binarization of deep networks},
  author={Hou, Lu and Yao, Quanming and Kwok, James T},
  journal={arXiv preprint arXiv:1611.01600},
  year={2016}
}


@article{wang2020minilm,
  title={Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers},
  author={Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.10957},
  year={2020}
}


@article{fan2019reducing,
  title={Reducing transformer depth on demand with structured dropout},
  author={Fan, Angela and Grave, Edouard and Joulin, Armand},
  journal={arXiv preprint arXiv:1909.11556},
  year={2019}
}


@article{raganato2020fixed,
  title={Fixed encoder self-attention patterns in transformer-based machine translation},
  author={Raganato, Alessandro and Scherrer, Yves and Tiedemann, J{\"o}rg},
  journal={arXiv preprint arXiv:2002.10260},
  year={2020}
}



@article{gordon2020compressing,
  title={Compressing bert: Studying the effects of weight pruning on transfer learning},
  author={Gordon, Mitchell A and Duh, Kevin and Andrews, Nicholas},
  journal={arXiv preprint arXiv:2002.08307},
  year={2020}
}


@article{ganesh2020compressing,
  title={Compressing large-scale transformer-based models: A case study on bert},
  author={Ganesh, Prakhar and Chen, Yao and Lou, Xin and Khan, Mohammad Ali and Yang, Yin and Chen, Deming and Winslett, Marianne and Sajjad, Hassan and Nakov, Preslav},
  journal={arXiv preprint arXiv:2002.11985},
  year={2020}
}

@article{michel2019sixteen,
  title={Are sixteen heads really better than one?},
  author={Michel, Paul and Levy, Omer and Neubig, Graham},
  journal={arXiv preprint arXiv:1905.10650},
  year={2019}
}





@article{bai2020binarybert,
  title={BinaryBERT: Pushing the Limit of BERT Quantization},
  author={Bai, Haoli and Zhang, Wei and Hou, Lu and Shang, Lifeng and Jin, Jing and Jiang, Xin and Liu, Qun and Lyu, Michael and King, Irwin},
  journal={arXiv preprint arXiv:2012.15701},
  year={2020}
}

@article{dehghani2018universal,
  title={Universal transformers},
  author={Dehghani, Mostafa and Gouws, Stephan and Vinyals, Oriol and Uszkoreit, Jakob and Kaiser, {\L}ukasz},
  journal={arXiv preprint arXiv:1807.03819},
  year={2018}
}

@article{lan2019albert,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{jin2021kdlsq,
  title={KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with Learned Step Size Quantization},
  author={Jin, Jing and Liang, Cai and Wu, Tiancheng and Zou, Liqin and Gan, Zhiliang},
  journal={arXiv preprint arXiv:2101.05938},
  year={2021}
}

@article{esser2019learned,
  title={Learned step size quantization},
  author={Esser, Steven K and McKinstry, Jeffrey L and Bablani, Deepika and Appuswamy, Rathinakumar and Modha, Dharmendra S},
  journal={arXiv preprint arXiv:1902.08153},
  year={2019}
}

@article{zhang2020ternarybert,
  title={Ternarybert: Distillation-aware ultra-low bit bert},
  author={Zhang, Wei and Hou, Lu and Yin, Yichun and Shang, Lifeng and Chen, Xiao and Jiang, Xin and Liu, Qun},
  journal={arXiv preprint arXiv:2009.12812},
  year={2020}
}

@inproceedings{zadeh2020gobo,
  title={Gobo: Quantizing attention-based nlp models for low latency and energy efficient inference},
  author={Zadeh, Ali Hadi and Edo, Isak and Awad, Omar Mohamed and Moshovos, Andreas},
  booktitle={2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)},
  pages={811--824},
  year={2020},
  organization={IEEE}
}

@article{fan2020training,
  title={Training with quantization noise for extreme fixed-point compression},
  author={Fan, Angela and Stock, Pierre and Graham, Benjamin and Grave, Edouard and Gribonval, Remi and Jegou, Herve and Joulin, Armand},
  journal={arXiv preprint arXiv:2004.07320},
  year={2020}
}

@article{waring1779vii,
  title={Vii. problems concerning interpolations},
  author={Waring, Edward},
  journal={Philosophical transactions of the royal society of London},
  year={1779},
  publisher={The Royal Society London}
}

@book{stewart1996afternotes,
  title={Afternotes on numerical analysis},
  author={Stewart, Gilbert W},
  year={1996},
  publisher={SIAM}
}

@inproceedings{dolan2005automatically,
  title={Automatically constructing a corpus of sentential paraphrases},
  author={Dolan, William B and Brockett, Chris},
  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},
  year={2005}
}

@article{cer2017semeval,
  title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},
  author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
  journal={arXiv preprint arXiv:1708.00055},
  year={2017}
}

@article{williams2017broad,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1704.05426},
  year={2017}
}

@article{iyer2017first,
  title={First Quora Dataset Release: Question Pairs.(2017)},
  author={Iyer, Shankar and Dandekar, Nikhil and Csernai, Kornl},
  journal={URL https://data. quora. com/First-Quora-Dataset-Release-Question-Pairs},
  year={2017}
}

@article{warstadt2019neural,
  title={Neural network acceptability judgments},
  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={625--641},
  year={2019},
  publisher={MIT Press}
}

@article{rajpurkar2016squad,
  title={{SQuAD}: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  journal={arXiv preprint arXiv:1606.05250},
  year={2016}
}

@inproceedings{dagan2005pascal,
  title={The PASCAL recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  pages={177--190},
  year={2005},
  organization={Springer}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@inproceedings{levesque2012winograd,
  title={The winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},
  year={2012},
  organization={Citeseer}
}

@article{rosset2019turing,
  title={Turing-{NLG}: A 17-billion-parameter language model by microsoft},
  author={Rosset, C},
  journal={Microsoft Blog},
  year={2019}
}

@article{shoeybi2019megatron,
  title={Megatron-{LM}: Training multi-billion parameter language models using gpu model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{lai2018cmsis,
  title={{CMSIS-NN}: Efficient neural network kernels for arm cortex-m cpus},
  author={Lai, Liangzhen and Suda, Naveen and Chandra, Vikas},
  journal={arXiv preprint arXiv:1801.06601},
  year={2018}
}

@book{crandall2006prime,
  title={Prime numbers: a computational perspective},
  author={Crandall, Richard and Pomerance, Carl B},
  volume={182},
  year={2006},
  publisher={Springer Science \& Business Media}
}

@article{conti2020technical,
  title={Technical Report: NEMO DNN Quantization for Deployment Model},
  author={Conti, Francesco},
  journal={arXiv preprint arXiv:2004.05930},
  year={2020}
}

@inproceedings{kwon2018co,
  title={Co-design of deep neural nets and neural net accelerators for embedded vision applications},
  author={Kwon, Kiseok and Amid, Alon and Gholami, Amir and Wu, Bichen and Asanovic, Krste and Keutzer, Kurt},
  booktitle={2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@article{li2016ternary,
  title={Ternary weight networks},
  author={Li, Fengfu and Zhang, Bo and Liu, Bin},
  journal={arXiv preprint arXiv:1605.04711},
  year={2016}
}

@article{courbariaux2016binarized,
  title={Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1},
  author={Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1602.02830},
  year={2016}
}

@inproceedings{howard2019searching,
  title={Searching for {MobilenetV3}},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1314--1324},
  year={2019}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units ({GELU}s)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@article{devlin2018bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@misc{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}

@article{dodge2020fine,
  title={Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping},
  author={Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
  journal={arXiv preprint arXiv:2002.06305},
  year={2020}
}

@article{liu2019roberta,
  title={{RoBERTa}: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{krishnamoorthi2018quantizing,
  title={Quantizing deep convolutional networks for efficient inference: A whitepaper},
  author={Krishnamoorthi, Raghuraman},
  journal={arXiv preprint arXiv:1806.08342},
  year={2018}
}

@article{wu2020integer,
  title={Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation},
  author={Wu, Hao and Judd, Patrick and Zhang, Xiaojie and Isaev, Mikhail and Micikevicius, Paulius},
  journal={arXiv preprint arXiv:2004.09602},
  year={2020}
}

@article{zafrir2019q8bert,
  title={{Q8BERT}: Quantized 8bit bert},
  author={Zafrir, Ofir and Boudoukh, Guy and Izsak, Peter and Wasserblat, Moshe},
  journal={arXiv preprint arXiv:1910.06188},
  year={2019}
}

@article{bhandare2019efficient,
  title={Efficient 8-bit quantization of transformer neural machine language translation model},
  author={Bhandare, Aishwarya and Sripathi, Vamsi and Karkada, Deepthi and Menon, Vivek and Choi, Sun and Datta, Kushal and Saletore, Vikram},
  journal={arXiv preprint arXiv:1906.00532},
  year={2019}
}

@article{wu2018mixed,
  title={Mixed precision quantization of convnets via differentiable neural architecture search},
  author={Wu, Bichen and Wang, Yanghan and Zhang, Peizhao and Tian, Yuandong and Vajda, Peter and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1812.00090},
  year={2018}
}


@inproceedings{wu2016quantized,
  title={Quantized convolutional neural networks for mobile devices},
  author={Wu, Jiaxiang and Leng, Cong and Wang, Yuhang and Hu, Qinghao and Cheng, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4820--4828},
  year={2016}
}

@inproceedings{jacob2018quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2704--2713},
  year={2018}
}


@article{wang2018glue,
  title={{GLUE}: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@BOOK{Mah-mat-rev_BOOK,
  author =       {Michael W Mahoney},
  title =        {Randomized algorithms for matrices and data},
  publisher =    {NOW Publishers},
  year =         {2011},
  address =      {Boston},
  series =       {Foundations and Trends in Machine Learning},
}

@INCOLLECTION{RandNLA_PCMIchapter_chapter,
  author =       {Petros Drineas and Michael W Mahoney},
  title =        {Lectures on Randomized Numerical Linear Algebra},
  booktitle =    {The Mathematics of Data},
  year =         {2018},
  pages =        {1--48},
  series =       {IAS/Park City Mathematics Series},
  publisher =    {AMS/IAS/SIAM},
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting on association for computational linguistics},
  pages={311--318},
  year={2002},
  organization={Association for Computational Linguistics}
}

@inproceedings{wang2019learning,
  title={Learning Deep Transformer Models for Machine Translation},
  author={Wang, Qiang and Li, Bei and Xiao, Tong and Zhu, Jingbo and Li, Changliang and Wong, Derek F and Chao, Lidia S},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={1810--1822},
  year={2019}
}

@article{mahoney2011large,
  title={Large text compression benchmark},
  author={Mahoney, Matt}
}

@article{younesshapes,
  title={Shapes and Diffeomorphisms},
  author={Younes, Laurent},
  journal={Springer Science \& Business Media}
}

@article{turing1990chemical,
  title={The chemical basis of morphogenesis},
  author={Turing, Alan Mathison},
  journal={Bulletin of mathematical biology},
  volume={52},
  number={1-2},
  pages={153--197},
  year={1952},
  publisher={Springer}
}

@BOOK{lions72,
  title = {Some Aspects of the Optimal Control of Distributed Parameter Systems},
  publisher = {SIAM},
  year = {1972},
  author = {Jacques-Louis Lions}
}

@book{rosenblatt1957perceptron,
  title={The perceptron, a perceiving and recognizing automaton Project Para},
  author={Rosenblatt, Frank},
  year={1957},
  publisher={Cornell Aeronautical Laboratory}
}

@article{rumelhart1988learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and others},
  journal={Cognitive modeling},
  volume={5},
  number={3},
  pages={1},
  year={1988}
}

@article{minsky1969perceptron,
  title={Perceptron: an introduction to computational geometry},
  author={Minsky, Marvin and Papert, Seymour},
  journal={The MIT Press, Cambridge, expanded edition},
  volume={19},
  number={88},
  pages={2},
  year={1969}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Elsevier}
}


@InProceedings{simonyan2014very,
  author       = "Simonyan, K. and Zisserman, A.",
  title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  booktitle    = "International Conference on Learning Representations",
  year         = "2015",
}



@inproceedings{szegedy2016rethinking,
  title={Rethinking the {Inception} architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@inproceedings{ma2018shufflenet,
  title={Shufflenet {V2}: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={116--131},
  year={2018}
}

@inproceedings{sandler2018mobilenetv2,
  title={{MobilenetV2}: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4510--4520},
  year={2018}
}


@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={International Conference on Learning Representations},
  year={2016}
}


@article{howard2017mobilenets,
  title={{MobileNets}: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}
@article{iandola2016squeezenet,
  title={{SqueezeNet}: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},
  author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1602.07360},
  year={2016}
}
@inproceedings{rastegari2016xnor,
  title={{XNOR-Net}: Imagenet classification using binary convolutional neural networks},
  author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
  booktitle={European Conference on Computer Vision},
  pages={525--542},
  year={2016},
  organization={Springer}
}

@inproceedings{courbariaux2015binaryconnect,
  title={Binary{C}onnect: Training deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Advances in neural information processing systems},
  pages={3123--3131},
  year={2015}
}

@inproceedings{krogh1992simple,
  title={A simple weight decay can improve generalization},
  author={Krogh, Anders and Hertz, John A},
  booktitle={Advances in neural information processing systems},
  pages={950--957},
  year={1992}
}


@inproceedings{grosse2016kronecker,
  title={A Kronecker-factored approximate Fisher matrix for convolution layers},
  author={Grosse, Roger and Martens, James},
  booktitle={International Conference on Machine Learning},
  pages={573--582},
  year={2016}
}

@inproceedings{redmon2017yolo9000,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7263--7271},
  year={2017}
}


@inproceedings{sharma2018bit,
  title={Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural networks},
  author={Sharma, Hardik and Park, Jongse and Suda, Naveen and Lai, Liangzhen and Chau, Benson and Chandra, Vikas and Esmaeilzadeh, Hadi},
  booktitle={Proceedings of the 45th Annual International Symposium on Computer Architecture},
  pages={764--775},
  year={2018},
  organization={IEEE Press}
}

@inproceedings{bismo,
author = {Umuroglu, Yaman and Rasnayake, Lahiru and Sjalander, Magnus},
title = {BISMO: A Scalable Bit-Serial Matrix Multiplication Overlay for Reconfigurable Computing},
booktitle = {Field Programmable Logic and Applications (FPL), 2018 28th International Conference on},
series = {FPL '18},
year = {2018}
}

@article{li2016pruning,
  title={Pruning filters for efficient convnets},
  author={Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
  journal={arXiv preprint arXiv:1608.08710},
  year={2016}
}

@article{molchanov2016pruning,
  title={Pruning convolutional neural networks for resource efficient inference},
  author={Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  journal={arXiv preprint arXiv:1611.06440},
  year={2016}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@article{shallue2018measuring,
  title={Measuring the effects of data parallelism on neural network training},
  author={Shallue, Christopher J and Lee, Jaehoon and Antognini, Joe and Sohl-Dickstein, Jascha and Frostig, Roy and Dahl, George E},
  journal={arXiv preprint arXiv:1811.03600},
  year={2018}
}

@article{osawa2018second,
  title={Second-order Optimization Method for Large Mini-batch: Training ResNet-50 on ImageNet in 35 Epochs},
  author={Osawa, Kazuki and Tsuji, Yohei and Ueno, Yuichiro and Naruse, Akira and Yokota, Rio and Matsuoka, Satoshi},
  journal={arXiv preprint arXiv:1811.12019},
  year={2018}
}

@article{ba2016distributed,
  title={Distributed second-order optimization using Kronecker-factored approximations},
  author={Ba, Jimmy and Grosse, Roger and Martens, James},
  year={2016}
}

@article{KFAC-G15,
  author    = {James Martens and
               Roger B. Grosse},
  title     = {Optimizing Neural Networks with Kronecker-factored Approximate Curvature},
  journal   = {CoRR},
  volume    = {abs/1503.05671},
  year      = {2015},
  url       = {http://arxiv.org/abs/1503.05671},
  archivePrefix = {arXiv},
  eprint    = {1503.05671},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MartensG15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
wd-kfac,
title={Three Mechanisms of Weight Decay Regularization},
author={Guodong Zhang and Chaoqi Wang and Bowen Xu and Roger Grosse},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{FACEBOOK-IMAGENET-1H,
  author    = {Priya Goyal and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Pieter Noordhuis and
               Lukasz Wesolowski and
               Aapo Kyrola and
               Andrew Tulloch and
               Yangqing Jia and
               Kaiming He},
  title     = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},
  journal   = {CoRR},
  volume    = {abs/1706.02677},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02677},
  archivePrefix = {arXiv},
  eprint    = {1706.02677},
  timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GoyalDGNWKTJH17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{GOOG-2M-IMAGENET,
  author    = {Yang You and
               Zhao Zhang and
               Cho{-}Jui Hsieh and
               James Demmel},
  title     = {100-epoch ImageNet Training with AlexNet in 24 Minutes},
  journal   = {CoRR},
  volume    = {abs/1709.05011},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.05011},
  archivePrefix = {arXiv},
  eprint    = {1709.05011},
  timestamp = {Mon, 13 Aug 2018 16:47:54 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-05011},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ma2017power,
  title={The power of interpolation: Understanding the effectiveness of SGD in modern over-parametrized learning},
  author={Ma, Siyuan and Bassily, Raef and Belkin, Mikhail},
  journal={arXiv preprint arXiv:1712.06559},
  year={2017}
}

@article{OpenAI-EMP-LBS,
  author    = {Sam McCandlish and
               Jared Kaplan and
               Dario Amodei and
               OpenAI Dota Team},
  title     = {An Empirical Model of Large-Batch Training},
  journal   = {CoRR},
  volume    = {abs/1812.06162},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06162},
  archivePrefix = {arXiv},
  eprint    = {1812.06162},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1812-06162},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Noah-EMP-CRIT-BS,
  author    = {Noah Golmant and
               Nikita Vemuri and
               Zhewei Yao and
               Vladimir Feinberg and
               Amir Gholami and
               Kai Rothauge and
               Michael W. Mahoney and
               Joseph Gonzalez},
  title     = {On the Computational Inefficiency of Large Batch Sizes for Stochastic
               Gradient Descent},
  journal   = {CoRR},
  volume    = {abs/1811.12941},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.12941},
  archivePrefix = {arXiv},
  eprint    = {1811.12941},
  timestamp = {Mon, 03 Dec 2018 07:50:28 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-12941},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{GOOG-LB-KFAC-HYPO,
  author    = {Christopher J. Shallue and
               Jaehoon Lee and
               Joseph M. Antognini and
               Jascha Sohl{-}Dickstein and
               Roy Frostig and
               George E. Dahl},
  title     = {Measuring the Effects of Data Parallelism on Neural Network Training},
  journal   = {CoRR},
  volume    = {abs/1811.03600},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.03600},
  archivePrefix = {arXiv},
  eprint    = {1811.03600},
  timestamp = {Fri, 23 Nov 2018 12:43:51 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-03600},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{gholami2017integrated,
  title={Integrated Model, Batch and Domain Parallelism in Training Neural Networks},
  author={Gholami, Amir and Azad, Ariful and Jin, Peter and Keutzer, Kurt and Buluc, Aydin},
  journal={ACM Symposium on Parallelism in Algorithms and Architectures(SPAA'18)},
note={\href{https://arxiv.org/pdf/1712.04432.pdf}{[PDF]}},
  year={2018}
}

@inproceedings{zhang2015deep,
  title={Deep learning with elastic averaging SGD},
  author={Zhang, Sixin and Choromanska, Anna E and LeCun, Yann},
  booktitle={Advances in Neural Information Processing Systems},
  pages={685--693},
  year={2015}
}

@article{jia2018highly,
  title={Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes},
  author={Jia, Xianyan and Song, Shutao and He, Wei and Wang, Yangzihao and Rong, Haidong and Zhou, Feihu and Xie, Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei and others},
  journal={arXiv preprint arXiv:1807.11205},
  year={2018}
}


@article{bertsimas2011theory,
  title={Theory and applications of robust optimization},
  author={Bertsimas, Dimitris and Brown, David B and Caramanis, Constantine},
  journal={SIAM review},
  volume={53},
  number={3},
  pages={464--501},
  year={2011},
  publisher={SIAM}
}

@article{maleki2017parallel,
  title={Parallel Stochastic Gradient Descent with Sound Combiners},
  author={Maleki, Saeed and Musuvathi, Madanlal and Mytkowicz, Todd},
  journal={arXiv preprint arXiv:1705.08030},
  year={2017}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{smith2018bayesian,
  title={A bayesian perspective on generalization and stochastic gradient descent},
  author={Smith, Samuel L and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.06451},
  year={2018}
}

@article{smith2017don,
  title={Don't Decay the Learning Rate, Increase the Batch Size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Le, Quoc V},
  journal={arXiv preprint arXiv:1711.00489},
  year={2017}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch SGD: training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{yao2018hessian,
  title={Hessian-based Analysis of Large Batch Training and Robustness to Adversaries},
  author={Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}

@article{dinh2017sharp,
  title={Sharp minima can generalize for deep nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1703.04933},
  year={2017}
}

@inproceedings{smith2017cyclical,
  title={Cyclical learning rates for training neural networks},
  author={Smith, Leslie N},
  booktitle={Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on},
  pages={464--472},
  year={2017},
  organization={IEEE}
}

@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get M for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}

@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  institution={Citeseer}
}

@article{lin2013network,
  title={Network in network},
  author={Lin, Min and Chen, Qiang and Yan, Shuicheng},
  journal={arXiv preprint arXiv:1312.4400},
  year={2013}
}

@inproceedings{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  booktitle={NIPS workshop on deep learning and unsupervised feature learning},
  volume={2011},
  pages={5},
  year={2011}
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{shwartz2017opening,
  title={Opening the black box of deep neural networks via information},
  author={Shwartz-Ziv, Ravid and Tishby, Naftali},
  journal={arXiv preprint arXiv:1703.00810},
  year={2017}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@inproceedings{dauphin2014identifying,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2933--2941},
  year={2014}
}

@article{devarakonda2017adabatch,
  title={AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks},
  author={Devarakonda, Aditya and Naumov, Maxim and Garland, Michael},
  journal={arXiv preprint arXiv:1712.02029},
  year={2017}
}


@article{zhu2018anisotropic,
  title={The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  journal={arXiv preprint arXiv:1803.00195},
  year={2018}
}

@article{friedlander2012hybrid,
  title={Hybrid deterministic-stochastic methods for data fitting},
  author={Friedlander, Michael P and Schmidt, Mark},
  journal={SIAM Journal on Scientific Computing},
  volume={34},
  number={3},
  pages={A1380--A1405},
  year={2012},
  publisher={SIAM}
}

@article{balles2016coupling,
  title={Coupling adaptive batch sizes with learning rates},
  author={Balles, Lukas and Romero, Javier and Hennig, Philipp},
  journal={arXiv preprint arXiv:1612.05086},
  year={2016}
}

@inproceedings{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1731--1741},
  year={2017}
}

@article{you2017scaling,
  title={Scaling sgd batch size to 32k for imagenet training},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}
@article{puri2018large,
  title={Large Scale Language Modeling: Converging on 40GB of Text in Four Hours},
  author={Puri, Raul and Kirby, Robert and Yakovenko, Nikolai and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1808.01371},
  year={2018}
}

@article{goodfellow6572explaining,
  title={Explaining and harnessing adversarial examples (2014)},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}


@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{gholami2018squeezenext,
  title={{SqueezeNext}: Hardware-Aware Neural Network Design},
  author={Gholami, Amir and Kwon, Kiseok and Wu, Bichen and Tai, Zizheng and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Keutzer, Kurt},
  journal={Workshop paper in CVPR},
  year={2018}
}

@article{thakur2005optimization,
  title={Optimization of collective communication operations in MPICH},
  author={Thakur, Rajeev and Rabenseifner, Rolf and Gropp, William},
  journal={The International Journal of High Performance Computing Applications},
  volume={19},
  number={1},
  pages={49--66},
  year={2005},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{zheng2016asynchronous,
  title={Asynchronous stochastic gradient descent with delay compensation},
  author={Zheng, Shuxin and Meng, Qi and Wang, Taifeng and Chen, Wei and Yu, Nenghai and Ma, Zhi-Ming and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1609.08326},
  year={2016}
}

@inproceedings{agarwal2011distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  booktitle={Advances in Neural Information Processing Systems},
  pages={873--881},
  year={2011}
}

@article{el1997robust,
  title={Robust solutions to least-squares problems with uncertain data},
  author={El Ghaoui, Laurent and Lebret, Herv{\'e}},
  journal={SIAM Journal on matrix analysis and applications},
  volume={18},
  number={4},
  pages={1035--1064},
  year={1997},
  publisher={SIAM}
}

@inproceedings{xu2009robust,
  title={Robust regression and lasso},
  author={Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1801--1808},
  year={2009}
}

@article{xu2017second,
  title={Second-order optimization for non-convex machine learning: An empirical study},
  author={Xu, Peng and Roosta-Khorasan, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07827},
  year={2017}
}

@article{chen2018comparison,
  title={A comparison of second-order methods for deep convolutional neural networks},
  author={Chen, Patrick H and Hsieh, Cho-jui},
  journal={openreview under ICLR 2018},
  year={2018}
}

@inproceedings{martens2010deep,
  title={Deep learning via {H}essian-free optimization.},
  author={Martens, James},
  booktitle={ICML},
  volume={27},
  pages={735--742},
  year={2010}
}

@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2574--2582},
  year={2016}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={39--57},
  year={2017},
  organization={IEEE}
}

@article{kurakin2016adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1607.02533},
  year={2016}
}

@article{xu2017newton,
  title={Newton-type methods for non-convex optimization under inexact {H}essian information},
  author={Xu, Peng and Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07164},
  year={2017}
}

@inproceedings{yang2019synetgy,
  title={Synetgy: Algorithm-hardware co-design for {C}onv{N}et accelerators on embedded {FPGA}s},
  author={Yang, Yifan and Huang, Qijing and Wu, Bichen and Zhang, Tianjun and Ma, Liang and Gambardella, Giulio and Blott, Michaela and Lavagno, Luciano and Vissers, Kees and Wawrzynek, John and  Keutzer, Kurt},
  booktitle={Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  pages={23--32},
  year={2019},
  organization={ACM}
}

@article{ward2018adagrad,
  title={AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
  author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
  journal={arXiv preprint arXiv:1806.01811},
  year={2018}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@article{shaham2015understanding,
  title={Understanding adversarial training: Increasing local stability of neural nets through robust optimization},
  author={Shaham, Uri and Yamada, Yutaro and Negahban, Sahand},
  journal={arXiv preprint arXiv:1511.05432},
  year={2015}
}

@inproceedings{shrivastava2017learning,
  title={Learning from Simulated and Unsupervised Images through Adversarial Training.},
  author={Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Joshua and Wang, Wenda and Webb, Russell},
  booktitle={CVPR},
  volume={2},
  pages={5},
  year={2017}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{yao2018large,
  title={Large batch size training of neural networks with adversarial training and second-order information},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1810.01021},
  year={2018}
}

@misc{ginsburg2017tensor,
  title={Tensor processing using low precision format},
  author={Ginsburg, Boris and Nikolaev, Sergei and Kiswani, Ahmad and Wu, Hao and Gholaminejad, Amir and Kierat, Slawomir and Houston, Michael and Fit-Florea, Alex},
  year={2017},
  month=dec # "~28",
  publisher={Google Patents},
  note={US Patent App. 15/624,577}
}

@article{hubara2017quantized,
  title={Quantized neural networks: Training neural networks with low precision weights and activations},
  author={Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6869--6898},
  year={2017},
  publisher={JMLR. org}
}

@article{miyashita2016convolutional,
  title={Convolutional neural networks using logarithmic data representation},
  author={Miyashita, Daisuke and Lee, Edward H and Murmann, Boris},
  journal={arXiv preprint arXiv:1603.01025},
  year={2016}
}

@inproceedings{denton2014exploiting,
  title={Exploiting linear structure within convolutional networks for efficient evaluation},
  author={Denton, Emily L and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob},
  booktitle={Advances in neural information processing systems},
  pages={1269--1277},
  year={2014}
}

@book{asanovic1991experimental,
  title={Experimental determination of precision requirements for back-propagation training of artificial neural networks},
  author={Asanovic, Krste and Morgan, Nelson},
  year={1991},
  publisher={International Computer Science Institute}
}


@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  booktitle={Advances in neural information processing systems},
  pages={1135--1143},
  year={2015}
}


@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press}
}

@article{wang2018haq,
  title={{HAQ}: Hardware-Aware Automated Quantization},
  author={Wang, Kuan and Liu, Zhijian and Lin, Yujun and Lin, Ji and Han, Song},
  journal={In Proceedings of  the IEEE  conference  on  computer  vision  and  pattern  recognition},
  year={2019}
}

@article{mao2017exploring,
  title={Exploring the regularity of sparse structure in convolutional neural networks},
  author={Mao, Huizi and Han, Song and Pool, Jeff and Li, Wenshuo and Liu, Xingyu and Wang, Yu and Dally, William J},
  journal={Workshop paper in CVPR},
  year={2017}
}


@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}


@inproceedings{park2018value,
  title={Value-aware quantization for training and inference of neural networks},
  author={Park, Eunhyeok and Yoo, Sungjoo and Vajda, Peter},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={580--595},
  year={2018}
}

@inproceedings{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6571--6583},
  year={2018}
}

@article{gholami2019anode,
  title={ANODE: Unconditionally Accurate Memory-Efficient Gradients for Neural ODEs},
  author={Gholami, Amir and Keutzer, Kurt and Biros, George},
  journal={arXiv preprint arXiv:1902.10298},
  year={2019}
}


@techreport{rosenblatt1961principles,
  title={Principles of neurodynamics. perceptrons and the theory of brain mechanisms},
  author={Rosenblatt, Frank},
  year={1961},
  institution={Cornell Aeronautical Lab Inc Buffalo NY}
}
@book{yan2009linear,
  title={Linear regression analysis: theory and computing},
  author={Yan, Xin and Su, Xiaogang},
  year={2009},
  publisher={World Scientific}
}



@book{gauss1809theoria,
  title={Theoria motus corporum coelestium in sectionibus conicis solem ambientium},
  author={Gauss, Carl Friedrich},
  volume={7},
  year={1809},
  publisher={Perthes et Besser}
}

@book{legendre1805nouvelles,
  title={Nouvelles m{\'e}thodes pour la d{\'e}termination des orbites des com{\`e}tes},
  author={Legendre, Adrien Marie},
  year={1805},
  publisher={F. Didot}
}


@article{mcculloch1943logical,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  pages={115--133},
  year={1943},
  publisher={Springer}
}


@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@book{rosenblatt1957perceptron,
  title={The perceptron, a perceiving and recognizing automaton Project Para},
  author={Rosenblatt, Frank},
  year={1957},
  publisher={Cornell Aeronautical Laboratory}
}



@article{weinan2017proposal,
  title={A proposal on machine learning via dynamical systems},
  author={Weinan, E},
  journal={Communications in Mathematics and Statistics},
  volume={5},
  number={1},
  pages={1--11},
  year={2017},
  publisher={Springer}
}
@article{haber2017stable,
  title={Stable architectures for deep neural networks},
  author={Haber, Eldad and Ruthotto, Lars},
  journal={Inverse Problems},
  volume={34},
  number={1},
  pages={014004},
  year={2017},
  publisher={IOP Publishing}
}
@article{ruthotto2018deep,
  title={Deep Neural Networks motivated by Partial Differential Equations},
  author={Ruthotto, Lars and Haber, Eldad},
  journal={arXiv preprint arXiv:1804.04272},
  year={2018}
}
@article{lu2017beyond,
  title={Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations},
  author={Lu, Yiping and Zhong, Aoxiao and Li, Quanzheng and Dong, Bin},
  journal={arXiv preprint arXiv:1710.10121},
  year={2017}
}
@article{ciccone2018nais,
  title={NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations},
  author={Ciccone, Marco and Gallieri, Marco and Masci, Jonathan and Osendorfer, Christian and Gomez, Faustino},
  journal={arXiv preprint arXiv:1804.07209},
  year={2018}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}

@inproceedings{tsuchida2018invariance,
  title={Invariance of Weight Distributions in Rectified MLPs},
  author={Tsuchida, Russell and Roosta-Khorasani, Farbod and Gallagher, Marcus},
  booktitle={International Conference on Machine Learning},
  pages={5002--5011},
  year={2018}
}




@article{ha2016hypernetworks,
  title={Hypernetworks},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  journal={arXiv preprint arXiv:1609.09106},
  year={2016}
}

@article{stanley2009hypercube,
  title={A hypercube-based encoding for evolving large-scale neural networks},
  author={Stanley, Kenneth O and D'Ambrosio, David B and Gauci, Jason},
  journal={Artificial life},
  volume={15},
  number={2},
  pages={185--212},
  year={2009},
  publisher={MIT Press}
}

@inproceedings{stanley2006exploiting,
  title={Exploiting regularity without development},
  author={Stanley, Kenneth O},
  booktitle={Proceedings of the AAAI Fall Symposium on Developmental Systems},
  pages={37},
  year={2006},
  organization={AAAI Press Menlo Park, CA}
}
@article{stanley2007compositional,
  title={Compositional pattern producing networks: A novel abstraction of development},
  author={Stanley, Kenneth O},
  journal={Genetic programming and evolvable machines},
  volume={8},
  number={2},
  pages={131--162},
  year={2007},
  publisher={Springer}
}




@inproceedings{angeline1995morphogenic,
  title={Morphogenic Evolutionary Computations: Introduction, Issues and Example.},
  author={Angeline, Peter J},
  booktitle={Evolutionary Programming},
  pages={387--401},
  year={1995}
}

% -------


@article{lindenmayer1968mathematical,
  title={Mathematical models for cellular interactions in development I. Filaments with one-sided inputs},
  author={Lindenmayer, Aristid},
  journal={Journal of theoretical biology},
  volume={18},
  number={3},
  pages={280--299},
  year={1968},
  publisher={Elsevier}
}


@inproceedings{belew1993evolving,
  title={Evolving Aesthetic Sorting Networks Using Developmental Grammars.},
  author={Belew, Richard K and Kammeyer, Thomas E},
  booktitle={ICGA},
  pages={629},
  year={1993},
  organization={Citeseer}
}

@inproceedings{bentley1999three,
  title={Three ways to grow designs: A comparison of embryogenies for an evolutionary design problem},
  author={Bentley, Peter and Kumar, Sanjeev},
  booktitle={Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 1},
  pages={35--43},
  year={1999},
  organization={Morgan Kaufmann Publishers Inc.}
}

@inproceedings{dellaert1996developmental,
  title={A developmental model for the evolution of complete autonomous agents},
  author={Dellaert, Frank and Beer, Randall D},
  booktitle={Proceedings of the fourth international conference on simulation of adaptive behavior},
  pages={393--401},
  year={1996},
  organization={MIT Press Cambridge, MA}
}

@inproceedings{eggenberger1997evolving,
  title={Evolving morphologies of simulated 3D organisms based on differential gene expression},
  author={Eggenberger, Peter},
  booktitle={Proceedings of the fourth european conference on Artificial Life},
  pages={205--213},
  year={1997}
}


@article{hornby2002creating,
  title={Creating high-level components with a generative representation for body-brain evolution},
  author={Hornby, Gregory S and Pollack, Jordan B},
  journal={Artificial life},
  volume={8},
  number={3},
  pages={223--246},
  year={2002},
  publisher={MIT Press}
}

@inproceedings{koutnik2010evolving,
  title={Evolving neural networks in compressed weight space},
  author={Koutnik, Jan and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 12th annual conference on Genetic and evolutionary computation},
  pages={619--626},
  year={2010},
  organization={ACM}
}



@inproceedings{fernando2016convolution,
  title={Convolution by evolution: Differentiable pattern producing networks},
  author={Fernando, Chrisantha and Banarse, Dylan and Reynolds, Malcolm and Besse, Frederic and Pfau, David and Jaderberg, Max and Lanctot, Marc and Wierstra, Daan},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference 2016},
  pages={109--116},
  year={2016},
  organization={ACM}
}


@article{moczulski2015acdc,
  title={Acdc: A structured efficient linear layer},
  author={Moczulski, Marcin and Denil, Misha and Appleyard, Jeremy and de Freitas, Nando},
  journal={arXiv preprint arXiv:1511.05946},
  year={2015}
}

@article{schmidhuber1992learning,
  title={Learning to control fast-weight memories: An alternative to dynamic recurrent networks},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={4},
  number={1},
  pages={131--139},
  year={1992},
  publisher={MIT Press}
}

@inproceedings{schmidhuber1993self,
  title={A ‘self-referential’weight matrix},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={International Conference on Artificial Neural Networks},
  pages={446--450},
  year={1993},
  organization={Springer}
}


@article{gholami2016inverse,
  title={An inverse problem formulation for parameter estimation of a reaction--diffusion model of low grade gliomas},
  author={Gholami, Amir and Mang, Andreas and Biros, George},
  journal={Journal of mathematical biology},
  volume={72},
  number={1-2},
  pages={409--433},
  year={2016},
  publisher={Springer}
}
@ONLINE{anonymous,
  title = {Anonymized for Review},
  month = Jan,
  year = 2021
}

@article{avron2011randomized,
  title={Randomized algorithms for estimating the trace of an implicit symmetric positive semi-definite matrix},
  author={Avron, Haim and Toledo, Sivan},
  journal={Journal of the ACM (JACM)},
  volume={58},
  number={2},
  pages={8},
  year={2011},
  publisher={ACM}
}

@article{bai1996some,
  title={Some large-scale matrix computation problems},
  author={Bai, Zhaojun and Fahey, Gark and Golub, Gene},
  journal={Journal of Computational and Applied Mathematics},
  volume={74},
  number={1-2},
  pages={71--89},
  year={1996},
  publisher={Elsevier}
}

@article{ubaru2017fast,
  title={Fast Estimation of tr(f(A)) via Stochastic {L}anczos Quadrature},
  author={Ubaru, Shashanka and Chen, Jie and Saad, Yousef},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={38},
  number={4},
  pages={1075--1099},
  year={2017},
  publisher={SIAM}
}

@article{lin2016approximating,
  title={Approximating spectral densities of large matrices},
  author={Lin, Lin and Saad, Yousef and Yang, Chao},
  journal={SIAM review},
  volume={58},
  number={1},
  pages={34--65},
  year={2016},
  publisher={SIAM}
}

@book{golub2009matrices,
  title={Matrices, moments and quadrature with applications},
  author={Golub, Gene H and Meurant, G{\'e}rard},
  year={2009},
  publisher={Princeton University Press}
}

@article{golub1969calculation,
  title={Calculation of {G}auss quadrature rules},
  author={Golub, Gene H and Welsch, John H},
  journal={Mathematics of computation},
  volume={23},
  number={106},
  pages={221--230},
  year={1969}
}

@article{lepikhin2020gshard,
  title={{GShard}: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={arXiv preprint arXiv:2006.16668},
  year={2020}
}

@inproceedings{yang2019xlnet,
  title={{XLNet}: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={Advances in neural information processing systems},
  pages={5753--5763},
  year={2019}
}

@inproceedings{dai2019transformer,
  title={Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime G and Le, Quoc and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2978--2988},
  year={2019}
}

@article{ghorbani2019investigation,
  title={An investigation into neural net optimization via {H}essian eigenvalue density},
  author={Ghorbani, Behrooz and Krishnan, Shankar and Xiao, Ying},
  journal={arXiv preprint arXiv:1901.10159},
  year={2019}
}

@article{sagun2016eigenvalues,
  title={Eigenvalues of the {H}essian in deep learning: Singularity and beyond},
  author={Sagun, Levent and Bottou, Leon and LeCun, Yann},
  journal={arXiv preprint arXiv:1611.07476},
  year={2016}
}

@article{vershynin2010introduction,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Vershynin, Roman},
  journal={arXiv preprint arXiv:1011.3027},
  year={2010}
}

@ONLINE{pyhessian,
  title = {https://github.com/amirgholami/PyHessian.git},
  month = Sep,
  year = 2019
}

@ONLINE{armcortexm,
  author={{ARM}},
  title = {{Cortex-M}, https://developer.arm.com/ip-products/processors/cortex-m},
  year = 2020
}

@ONLINE{tensorrtbert,
  author={ Mukherjee, Purnendu and Weill, Eddie and Taneja, Rohit and Onofrio, Davide and Ko, Young-Jun and Sharma, Siddharth},
  title = {Real-Time Natural Language Understanding with BERT Using TensorRT, hhttps://developer.nvidia.com/blog/nlu-with-tensorrt-bert/},
  year = 2019
}

@ONLINE{tensorrt,
  author={{NVIDIA}},
  title = {Tensor{RT}: https://developer.nvidia.com/tensorrt},
  year={2018}
}

@inproceedings{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2483--2493},
  year={2018}
}



@article{martin2019traditional,
  title={Traditional and heavy-tailed self regularization in neural network models},
  author={Martin, Charles H and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1901.08276},
  year={2019}
}


@article{clevert2015fast,
  title={Fast and accurate deep network learning by exponential linear units (elus)},
  author={Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:1511.07289},
  year={2015}
}

@inproceedings{klambauer2017self,
  title={Self-normalizing neural networks},
  author={Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  booktitle={Advances in neural information processing systems},
  pages={971--980},
  year={2017}
}

@article{mahoney2009cur,
  title={{CUR} matrix decompositions for improved data analysis},
  author={Mahoney, Michael W and Drineas, Petros},
  journal={Proceedings of the National Academy of Sciences},
  volume={106},
  number={3},
  pages={697--702},
  year={2009},
  publisher={National Acad Sciences}
}

@article{drineas2006fast,
  title={Fast Monte Carlo algorithms for matrices {II}: Computing a low-rank approximation to a matrix},
  author={Drineas, Petros and Kannan, Ravi and Mahoney, Michael W},
  journal={SIAM Journal on computing},
  volume={36},
  number={1},
  pages={158--183},
  year={2006},
  publisher={SIAM}
}

@inproceedings{becker1988improving,
  title={Improving the convergence of back-propagation learning with second order methods},
  author={Becker, Sue and Le Cun, Yann},
  booktitle={Proceedings of the 1988 connectionist models summer school},
  pages={29--37},
  year={1988}
}

@article{sagun2017empirical,
  title={Empirical analysis of the hessian of over-parametrized neural networks},
  author={Sagun, Levent and Evci, Utku and Guney, V Ugur and Dauphin, Yann and Bottou, Leon},
  journal={arXiv preprint arXiv:1706.04454},
  year={2017}
}



@article{papyan2018full,
  title={The full spectrum of deep net hessians at scale: Dynamics with sample size},
  author={Papyan, Vardan},
  journal={arXiv preprint arXiv:1811.07062},
  year={2018}
}


@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@inproceedings{pennington2017geometry,
  title={Geometry of neural network loss surfaces via random matrix theory},
  author={Pennington, Jeffrey and Bahri, Yasaman},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2798--2806},
  year={2017},
  organization={JMLR. org}
}



@inproceedings{yao2019trust,
  title={Trust region based adversarial attack on neural networks},
  author={Yao, Zhewei and Gholami, Amir and Xu, Peng and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={11350--11359},
  year={2019}
}

@inproceedings{xu2016sub,
  title={Sub-sampled {N}ewton methods with non-uniform sampling},
  author={Xu, Peng and Yang, Jiyan and Roosta-Khorasani, Farbod and R{\'e}, Christopher and Mahoney, Michael W},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3000--3008},
  year={2016}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{byrd2011use,
  title={On the use of stochastic {H}essian information in optimization methods for machine learning},
  author={Byrd, Richard H and Chin, Gillian M and Neveitt, Will and Nocedal, Jorge},
  journal={SIAM Journal on Optimization},
  volume={21},
  number={3},
  pages={977--995},
  year={2011},
  publisher={SIAM}
}

@article{erdogdu2015convergence,
  title={Convergence rates of sub-sampled {N}ewton methods},
  author={Erdogdu, Murat A and Montanari, Andrea},
  journal={arXiv preprint arXiv:1508.02810},
  year={2015}
}

@article{roosta2016sub,
  title={Sub-sampled {N}ewton methods {I}: globally convergent algorithms},
  author={Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1601.04737},
  year={2016}
}

@book{conn2000trust,
	title={Trust region methods},
	author={Conn, Andrew R and Gould, Nicholas IM and Toint, Philippe L},
	series={Series on Optimization},
	publisher={SIAM},
	year={2000},
}

@article{nesterov2006cubic,
	title={{Cubic regularization of {N}ewton method and its global performance}},
	author={Nesterov, Yurii and Polyak, Boris T},
	journal={Mathematical Programming},
	volume={108},
	number={1},
	pages={177--205},
	year={2006},
	publisher={Springer}
}

@article{cartis2011adaptiveI,
	title={{Adaptive cubic regularisation methods for unconstrained optimization. Part I: motivation, convergence and numerical results}},
	author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
	journal={Mathematical Programming},
	volume={127},
	number={2},
	pages={245--295},
	year={2011},
	publisher={Springer}
}

@article{cartis2011adaptiveII,
	title={{Adaptive cubic regularisation methods for unconstrained optimization. Part II: worst-case function-and derivative-evaluation complexity}},
	author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
	journal={Mathematical programming},
	volume={130},
	number={2},
	pages={295--319},
	year={2011},
	publisher={Springer}
}

@article{yao2018inexact,
  title={Inexact non-convex {N}ewton-type methods},
  author={Yao, Zhewei and Xu, Peng and Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1802.06925},
  year={2018}
}

@article{xuNonconvexTheoretical2017,
	title={{Newton-Type Methods for Non-Convex Optimization Under Inexact Hessian Information}},
	author={Peng Xu and Farbod Roosta-Khorasani and Michael W. Mahoney},
	journal={arXiv preprint arXiv:1708.07164},
	year={2017}
}

@inproceedings{martens2015optimizing,
  title={Optimizing neural networks with {K}ronecker-factored approximate curvature},
  author={Martens, James and Grosse, Roger},
  booktitle={International conference on machine learning},
  pages={2408--2417},
  year={2015}
}

@article{krishnan2017neumann,
  title={Neumann optimizer: A practical optimization algorithm for deep neural networks},
  author={Krishnan, Shankar and Xiao, Ying and Saurous, Rif A},
  journal={arXiv preprint arXiv:1712.03298},
  year={2017}
}

@article{xuNonconvexEmpirical2017,
	title={{Second-Order Optimization for Non-Convex Machine Learning: An Empirical Study}},
	author={Peng Xu and Farbod Roosta-Khorasani and Michael W. Mahoney},
	journal={arXiv preprint arXiv:1708.07827},
	year={2017}
}

@inproceedings{vatanen2013pushing,
  title={Pushing stochastic gradient towards second-order methods--backpropagation learning with transformations in nonlinearities},
  author={Vatanen, Tommi and Raiko, Tapani and Valpola, Harri and LeCun, Yann},
  booktitle={International Conference on Neural Information Processing},
  pages={442--449},
  year={2013},
  organization={Springer}
}

@inproceedings{lecun1991second,
  title={Second order properties of error surfaces: Learning time and generalization},
  author={LeCun, Yann and Kanter, Ido and Solla, Sara A},
  booktitle={Advances in neural information processing systems},
  pages={918--924},
  year={1991}
}

@article{sagun2016singularity,
  title={Singularity of the hessian in deep learning},
  author={Sagun, Levent and Bottou, L{\'e}on and LeCun, Yann},
  journal={arXiv preprint arXiv:1611.07476},
  year={2016}
}

@article{dong2019hawqv2,
  title={{HAWQ-V2}: {H}essian {A}ware trace-{W}eighted {Q}uantization of Neural Networks},
  author={Dong, Zhen and Yao, Zhewei and Arfeen, Daiyaan and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  journal={NeurIPS’19 workshop on Beyond First-Order Optimization Methods in Machine Learning.},
  year={2019}
}


@article{agarwal2016second,
  title={Second-order stochastic optimization in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={Journal of Machine Learning Research},
  volume={1050},
  pages={15},
  year={2016}
}

@article{dembo1982inexact,
  title={Inexact {N}ewton methods},
  author={Dembo, Ron S and Eisenstat, Stanley C and Steihaug, Trond},
  journal={SIAM Journal on Numerical analysis},
  volume={19},
  number={2},
  pages={400--408},
  year={1982},
  publisher={SIAM}
}

@article{pearlmutter1994fast,
  title={Fast exact multiplication by the {H}essian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}

@article{pilanci2017newton,
  title={Newton sketch: A near linear-time optimization algorithm with linear-quadratic convergence},
  author={Pilanci, Mert and Wainwright, Martin J},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={1},
  pages={205--245},
  year={2017},
  publisher={SIAM}
}

@article{pratt1998gauss,
  title={Gauss--{N}ewton and full {N}ewton methods in frequency--space seismic waveform inversion},
  author={Pratt, R Gerhard and Shin, Changsoo and Hick, GJ},
  journal={Geophysical Journal International},
  volume={133},
  number={2},
  pages={341--362},
  year={1998},
  publisher={Blackwell Publishing Ltd Oxford, UK}
}

@article{amari1998natural,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-Ichi},
  journal={Neural computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}

@article{bollapragada2018progressive,
  title={A progressive batching {L-BFGS} method for machine learning},
  author={Bollapragada, Raghu and Mudigere, Dheevatsa and Nocedal, Jorge and Shi, Hao-Jun Michael and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1802.05374},
  year={2018}
}

@article{liu1989limited,
  title={On the limited memory {BFGS} method for large scale optimization},
  author={Liu, Dong C and Nocedal, Jorge},
  journal={Mathematical programming},
  volume={45},
  number={1-3},
  pages={503--528},
  year={1989},
  publisher={Springer}
}

@inproceedings{ma2019inefficiency,
  title={Inefficiency of {K-FAC} for Large Batch Size Training},
  author={Ma, Linjian and Montague, Gabe and Ye, Jiayu and Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={Thirty-Fourth AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{lecun1990optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John S and Solla, Sara A},
  booktitle={Advances in neural information processing systems},
  pages={598--605},
  year={1990}
}






@article{bordes2009sgd,
  title={SGD-QN: Careful quasi-{N}ewton stochastic gradient descent},
  author={Bordes, Antoine and Bottou, L{\'e}on and Gallinari, Patrick},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={Jul},
  pages={1737--1754},
  year={2009}
}



@article{dennis1974characterization,
  title={A characterization of superlinear convergence and its application to quasi-{N}ewton methods},
  author={Dennis, John E and Mor{\'e}, Jorge J},
  journal={Mathematics of computation},
  volume={28},
  number={126},
  pages={549--560},
  year={1974}
}


@article{nocedal1980updating,
  title={Updating quasi-{N}ewton matrices with limited storage},
  author={Nocedal, Jorge},
  journal={Mathematics of computation},
  volume={35},
  number={151},
  pages={773--782},
  year={1980}
}



@inproceedings{schraudolph2007stochastic,
  title={A stochastic quasi-{N}ewton method for online convex optimization},
  author={Schraudolph, Nicol N and Yu, Jin and G{\"u}nter, Simon},
  booktitle={Artificial intelligence and statistics},
  pages={436--443},
  year={2007}
}



@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={International Conference on Learning Representations},
  year={2015}
}

@article{yao2019pyhessian,
  title={PyHessian: Neural Networks Through the Lens of the Hessian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael},
  journal={arXiv preprint arXiv:1912.07145},
  year={2019}
}

@article{ruder2016overview,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@article{chaudhari2019entropy,
  title={Entropy-sgd: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2019},
  number={12},
  pages={124018},
  year={2019},
  publisher={IOP Publishing}
}

@inproceedings{
loshchilov2017decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{you2017large,
  title={Large batch training of convolutional networks},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@inproceedings{you2019large,
  title={Large batch optimization for deep learning: Training bert in 76 minutes},
  author={You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{reddi2019convergence,
  title={On the convergence of adam and beyond},
  author={Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1904.09237},
  year={2019}
}

@inproceedings{
loshchilov2016sgdr,
title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018}
}

@inproceedings{singh2015layer,
  title={Layer-specific adaptive learning rates for deep networks},
  author={Singh, Bharat and De, Soham and Zhang, Yangmuzi and Goldstein, Thomas and Taylor, Gavin},
  booktitle={2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)},
  pages={364--368},
  year={2015},
  organization={IEEE}
}



@inproceedings{wang2018giant,
  title={GIANT: Globally improved approximate Newton method for distributed optimization},
  author={Wang, Shusen and Roosta, Fred and Xu, Peng and Mahoney, Michael W},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2332--2342},
  year={2018}
}

@inproceedings{schaul2013no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  booktitle={International Conference on Machine Learning},
  pages={343--351},
  year={2013}
}

@inproceedings{liu2020On,
title={On the Variance of the Adaptive Learning Rate and Beyond},
author={Liyuan Liu and Haoming Jiang and Pengcheng He and Weizhu Chen and Xiaodong Liu and Jianfeng Gao and Jiawei Han},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{wilson2017marginal,
  title={The marginal value of adaptive gradient methods in machine learning},
  author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4148--4158},
  year={2017}
}

@article{zeiler2012adadelta,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@article{bengio2015rmsprop,
  title={Rmsprop and equilibrated adaptive learning rates for nonconvex optimization},
  author={Bengio, Yoshua},
  journal={corr abs/1502.04390},
  year={2015}
}

@article{bekas2007estimator,
  title={An estimator for the diagonal of a matrix},
  author={Bekas, Costas and Kokiopoulou, Effrosyni and Saad, Yousef},
  journal={Applied numerical mathematics},
  volume={57},
  number={11-12},
  pages={1214--1229},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{ott2018scaling,
  title={Scaling Neural Machine Translation},
  author={Ott, Myle and Edunov, Sergey and Grangier, David and Auli, Michael},
  booktitle={Proceedings of the Third Conference on Machine Translation: Research Papers},
  pages={1--9},
  year={2018}
}

@inproceedings{ott2019fairseq,
  title = {{FairSeq}: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{zhang2019improving,
  title={Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention},
  author={Zhang, Biao and Titov, Ivan and Sennrich, Rico},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={897--908},
  year={2019}
}

@article{zhang2019fixup,
  title={Fixup initialization: Residual learning without normalization},
  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},
  journal={arXiv preprint arXiv:1901.09321},
  year={2019}
}


@article{zhang2019adam,
  title={Why ADAM Beats SGD for Attention Models},
  author={Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank J and Kumar, Sanjiv and Sra, Suvrit},
  journal={arXiv preprint arXiv:1912.03194},
  year={2019}
}

@article{naumov2019deep,
  title={Deep learning recommendation model for personalization and recommendation systems},
  author={Naumov, Maxim and Mudigere, Dheevatsa and Shi, Hao-Jun Michael and Huang, Jianyu and Sundaraman, Narayanan and Park, Jongsoo and Wang, Xiaodong and Gupta, Udit and Wu, Carole-Jean and Azzolini, Alisson G and others},
  journal={arXiv preprint arXiv:1906.00091},
  year={2019}
}

@inproceedings{mikolov2011empirical,
  title={Empirical evaluation and combination of advanced language modeling techniques},
  author={Mikolov, Tom{\'a}{\v{s}} and Deoras, Anoop and Kombrink, Stefan and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan},
  booktitle={Twelfth Annual Conference of the International Speech Communication Association},
  year={2011}
}

@inproceedings{merity2016pointer,
title={Pointer sentinel mixture models},
author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{ma2019tensorized,
  title={A tensorized transformer for language modeling},
  author={Ma, Xindian and Zhang, Peng and Zhang, Shuai and Duan, Nan and Hou, Yuexian and Zhou, Ming and Song, Dawei},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2229--2239},
  year={2019}
}

@ONLINE{adahessian,
  title = {https://github.com/amirgholami/ADAHESSIAN.git},
  month = May,
  year = 2020
}

@article{phang2018sentence,
  title={Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks},
  author={Phang, Jason and F{\'e}vry, Thibault and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1811.01088},
  year={2018}
}


@article{iandola2020squeezebert,
  title={SqueezeBERT: What can computer vision teach NLP about efficient neural networks?},
  author={Iandola, Forrest N and Shaw, Albert E and Krishna, Ravi and Keutzer, Kurt W},
  journal={arXiv preprint arXiv:2006.11316},
  year={2020}
}

@article{martens2014new,
  title={New insights and perspectives on the natural gradient method},
  author={Martens, James},
  journal={arXiv preprint arXiv:1412.1193},
  year={2014}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
}


@inproceedings{martens2011learning,
  title={Learning recurrent neural networks with hessian-free optimization},
  author={Martens, James and Sutskever, Ilya},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={1033--1040},
  year={2011},
  organization={Citeseer}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{mcmahan2010adaptive,
  title={Adaptive bound optimization for online convex optimization},
  author={McMahan, H Brendan and Streeter, Matthew},
  journal={arXiv preprint arXiv:1002.4908},
  year={2010}
}


@article{bollapragada2019exact,
  title={Exact and inexact subsampled Newton methods for optimization},
  author={Bollapragada, Raghu and Byrd, Richard H and Nocedal, Jorge},
  journal={IMA Journal of Numerical Analysis},
  volume={39},
  number={2},
  pages={545--578},
  year={2019},
  publisher={Oxford University Press}
}


@inproceedings{ge2015escaping,
  title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle={Conference on Learning Theory},
  pages={797--842},
  year={2015}
}

@inproceedings{jin2017escape,
  title={How to escape saddle points efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1724--1732},
  year={2017},
  organization={JMLR. org}
}

@article{levy2016power,
  title={The power of normalization: Faster evasion of saddle points},
  author={Levy, Kfir Y},
  journal={arXiv preprint arXiv:1611.04831},
  year={2016}
}



@article{agarwal2016finding,
  title={Finding approximate local minima for nonconvex optimization in linear time},
  author={Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
  journal={arXiv preprint arXiv:1611.01146},
  year={2016}
}

@article{carmon2018accelerated,
  title={Accelerated methods for nonconvex optimization},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1751--1772},
  year={2018},
  publisher={SIAM}
}
@article{reddi2017generic,
  title={A generic approach for escaping saddle points},
  author={Reddi, Sashank J and Zaheer, Manzil and Sra, Suvrit and Poczos, Barnabas and Bach, Francis and Salakhutdinov, Ruslan and Smola, Alexander J},
  journal={arXiv preprint arXiv:1709.01434},
  year={2017}
}


@article{byrd1995limited,
  title={A limited memory algorithm for bound constrained optimization},
  author={Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
  journal={SIAM Journal on scientific computing},
  volume={16},
  number={5},
  pages={1190--1208},
  year={1995},
  publisher={SIAM}
}

@article{gupta2018shampoo,
  title={Shampoo: Preconditioned stochastic tensor optimization},
  author={Gupta, Vineet and Koren, Tomer and Singer, Yoram},
  journal={arXiv preprint arXiv:1802.09568},
  year={2018}
}

@inproceedings{nesterov1983method,
  title={A method for unconstrained convex minimization problem with the rate of convergence O (1/k\^{} 2)},
  author={Nesterov, Yurii},
  booktitle={Doklady an ussr},
  volume={269},
  pages={543--547},
  year={1983}
}

@incollection{wang2017deep,
  title={Deep \& cross network for ad click predictions},
  author={Wang, Ruoxi and Fu, Bin and Fu, Gang and Wang, Mingliang},
  booktitle={Proceedings of the ADKDD'17},
  pages={1--7},
  year={2017},
}

@book{martens2016second,
  title={Second-order optimization for neural networks},
  author={Martens, James},
  year={2016},
  publisher={University of Toronto (Canada)}
}

@inproceedings{wu2019fbnet,
  title={{FBN}et: Hardware-aware efficient convnet design via differentiable neural architecture search},
  author={Wu, Bichen and Dai, Xiaoliang and Zhang, Peizhao and Wang, Yanghan and Sun, Fei and Wu, Yiming and Tian, Yuandong and Vajda, Peter and Jia, Yangqing and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10734--10742},
  year={2019}
}

@article{chen2019fast,
  title={Fast Evaluation and Approximation of the Gauss-Newton Hessian Matrix for the Multilayer Perceptron},
  author={Chen, Chao and Reiz, Severin and Yu, Chenhan and Bungartz, Hans-Joachim and Biros, George},
  journal={arXiv preprint arXiv:1910.12184},
  year={2019}
}
@article{tan2019efficientnet,
  title={Efficient{N}et: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}
@article{han2017efficient,
  title={Efficient methods and hardware for deep learning},
  author={Han, Song and Dally, B},
  journal={University Lecture},
  year={2017}
}


@inproceedings{yang2017designing,
  title={Designing energy-efficient convolutional neural networks using energy-aware pruning},
  author={Yang, Tien-Ju and Chen, Yu-Hsin and Sze, Vivienne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5687--5695},
  year={2017}
}


@article{yao2020hawqv3,
  title={{HAWQV3}: Dyadic Neural Network Quantization},
  author={Yao, Zhewei and Dong, Zhen and Zheng, Zhangcheng and Gholami, Amir and Yu, Jiali and Tan, Eric and Wang, Leyuan and Huang, Qijing and Wang, Yida and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2011.10680},
  year={2020}
}

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}
@inproceedings{wu2018shift,
  title={Shift: A zero flop, zero parameter alternative to spatial convolutions},
  author={Wu, Bichen and Wan, Alvin and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Golmant, Noah and Gholaminejad, Amir and Gonzalez, Joseph and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9127--9135},
  year={2018}
}
@inproceedings{chen2018tvm,
  title={$\{$TVM$\}$: An automated end-to-end optimizing compiler for deep learning},
  author={Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Shen, Haichen and Cowan, Meghan and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and others},
  booktitle={13th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 18)},
  pages={578--594},
  year={2018}
}

@article{schraudolph1999fast,
  title={A fast, compact approximation of the exponential function},
  author={Schraudolph, Nicol N},
  journal={Neural Computation},
  volume={11},
  number={4},
  pages={853--862},
  year={1999},
  publisher={MIT Press}
}


@techreport{thomas2004libm,
  title={The libm library and floatingpoint arithmetic in HP-UX for Itanium-based systems},
  author={Thomas, James W and Okada, John P and Markstein, Peter and Li, Ren-Chang},
  year={2004},
  institution={Technical report, Hewlett-Packard Company, Palo Alto, CA, USA}
}

@inproceedings{detrey2005parameterized,
  title={A parameterized floating-point exponential function for FPGAs},
  author={Detrey, J{\'e}r{\'e}mie and de Dinechin, Florent},
  booktitle={Proceedings. 2005 IEEE International Conference on Field-Programmable Technology, 2005.},
  pages={27--34},
  year={2005},
  organization={IEEE}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}
@inproceedings{ioannou2017deep,
  title={Deep roots: Improving cnn efficiency with hierarchical filter groups},
  author={Ioannou, Yani and Robertson, Duncan and Cipolla, Roberto and Criminisi, Antonio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1231--1240},
  year={2017}
}

@inproceedings{tan2019mnasnet,
  title={Mnasnet: Platform-aware neural architecture search for mobile},
  author={Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2820--2828},
  year={2019}
}

@article{liu2018darts,
  title={Darts: Differentiable architecture search},
  author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  journal={arXiv preprint arXiv:1806.09055},
  year={2018}
}

@article{zoph2016neural,
  title={Neural architecture search with reinforcement learning},
  author={Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1611.01578},
  year={2016}
}

@inproceedings{pham2018efficient,
  title={Efficient neural architecture search via parameters sharing},
  author={Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
  booktitle={International Conference on Machine Learning},
  pages={4095--4104},
  year={2018},
  organization={PMLR}
}

@article{kim2021bert,
  title={I-BERT: Integer-only BERT Quantization},
  author={Kim, Sehoon and Gholami, Amir and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2101.01321},
  year={2021}
}
@article{yu2021hessian,
  title={Hessian-Aware Pruning and Optimal Neural Implant},
  author={Yu, Shixing and Yao, Zhewei and Gholami, Amir and Dong, Zhen and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2101.08940},
  year={2021}
}

@article{chauvin1989back,
  title={A back propagation network with optimal use of hidden units},
  author={Chauvin, Y},
  journal={Advances in neural information processing},
  year={1989}
}

@article{hanson1988comparing,
  title={Comparing biases for minimal network construction with back-propagation},
  author={Hanson, Stephen and Pratt, Lorien},
  journal={Advances in neural information processing systems},
  volume={1},
  pages={177--185},
  year={1988}
}

@inproceedings{mozer1988skeletonization,
  title={Skeletonization: A technique for trimming the fat from a network via relevance assessment},
  author={Mozer, Michael C and Smolensky, Paul},
  booktitle={Proceedings of the 1st International Conference on Neural Information Processing Systems},
  pages={107--115},
  year={1988}
}


@article{chin2020one,
  title={One Weight Bitwidth to Rule Them All},
  author={Chin, Ting-Wu and Chuang, Pierce I-Jen and Chandra, Vikas and Marculescu, Diana},
  journal={arXiv preprint arXiv:2008.09916},
  year={2020}
}
@inproceedings{xiao2019autoprune,
  title={Autoprune: Automatic network pruning by regularizing auxiliary parameters},
  author={Xiao, Xia and Wang, Zigeng and Rajasekaran, Sanguthevar},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13681--13691},
  year={2019}
}

@inproceedings{luo2017thinet,
  title={Thinet: A filter level pruning method for deep neural network compression},
  author={Luo, Jian-Hao and Wu, Jianxin and Lin, Weiyao},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={5058--5066},
  year={2017}
}

@inproceedings{he2018amc,
  title={Amc: Automl for model compression and acceleration on mobile devices},
  author={He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={784--800},
  year={2018}
}
@inproceedings{yu2018nisp,
  title={Nisp: Pruning networks using neuron importance score propagation},
  author={Yu, Ruichi and Li, Ang and Chen, Chun-Fu and Lai, Jui-Hsin and Morariu, Vlad I and Han, Xintong and Gao, Mingfei and Lin, Ching-Yung and Davis, Larry S},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={9194--9203},
  year={2018}
}

@inproceedings{lin2018accelerating,
  title={Accelerating Convolutional Networks via Global \& Dynamic Filter Pruning.},
  author={Lin, Shaohui and Ji, Rongrong and Li, Yuchao and Wu, Yongjian and Huang, Feiyue and Zhang, Baochang},
  booktitle={IJCAI},
  pages={2425--2432},
  year={2018}
}

@inproceedings{huang2018data,
  title={Data-driven sparse structure selection for deep neural networks},
  author={Huang, Zehao and Wang, Naiyan},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={304--320},
  year={2018}
}

@article{gale2019state,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv preprint arXiv:1902.09574},
  year={2019}
}

@inproceedings{he2017channel,
  title={Channel pruning for accelerating very deep neural networks},
  author={He, Yihui and Zhang, Xiangyu and Sun, Jian},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1389--1397},
  year={2017}
}
@inproceedings{lin2020hrank,
  title={HRank: Filter Pruning using High-Rank Feature Map},
  author={Lin, Mingbao and Ji, Rongrong and Wang, Yan and Zhang, Yichen and Zhang, Baochang and Tian, Yonghong and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1529--1538},
  year={2020}
}


@article{wang2019eigendamage,
  title={Eigendamage: Structured pruning in the kronecker-factored eigenbasis},
  author={Wang, Chaoqi and Grosse, Roger and Fidler, Sanja and Zhang, Guodong},
  journal={arXiv preprint arXiv:1905.05934},
  year={2019}
}


@inproceedings{hassibi1993optimal,
  title={Optimal brain surgeon and general network pruning},
  author={Hassibi, Babak and Stork, David G and Wolff, Gregory J},
  booktitle={IEEE international conference on neural networks},
  pages={293--299},
  year={1993},
  organization={IEEE}
}
@inproceedings{he2019filter,
  title={Filter pruning via geometric median for deep convolutional neural networks acceleration},
  author={He, Yang and Liu, Ping and Wang, Ziwei and Hu, Zhilan and Yang, Yi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4340--4349},
  year={2019}
}


@inproceedings{liu2017learning,
  title={Learning efficient convolutional networks through network slimming},
  author={Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2736--2744},
  year={2017}
}


@inproceedings{buluc2008challenges,
  title={Challenges and advances in parallel sparse matrix-matrix multiplication},
  author={Buluc, Aydin and Gilbert, John R},
  booktitle={2008 37th International Conference on Parallel Processing},
  pages={503--510},
  year={2008},
  organization={IEEE}
}
@inproceedings{zhao2019variational,
  title={Variational convolutional neural network pruning},
  author={Zhao, Chenglong and Ni, Bingbing and Zhang, Jian and Zhao, Qiwei and Zhang, Wenjun and Tian, Qi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2780--2789},
  year={2019}
}




@article{park2020lookahead,
  title={Lookahead: a Far-Sighted Alternative of Magnitude-based Pruning},
  author={Park, Sejun and Lee, Jaeho and Mo, Sangwoo and Shin, Jinwoo},
  journal={arXiv preprint arXiv:2002.04809},
  year={2020}
}


@article{lee2018snip,
  title={Snip: Single-shot network pruning based on connection sensitivity},
  author={Lee, Namhoon and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  journal={arXiv preprint arXiv:1810.02340},
  year={2018}
}


@misc{zhuang2020adabelief,
      title={AdaBelief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients}, 
      author={Juntang Zhuang and Tommy Tang and Yifan Ding and Sekhar Tatikonda and Nicha Dvornek and Xenophon Papademetris and James S. Duncan},
      year={2020},
      eprint={2010.07468},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{reddi2018adaptive,
  title={Adaptive methods for nonconvex optimization},
  author={Reddi, S and Zaheer, Manzil and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
  booktitle={Proceeding of 32nd Conference on Neural Information Processing Systems (NIPS 2018)},
  year={2018}
}
@misc{liu2020variance,
      title={On the Variance of the Adaptive Learning Rate and Beyond}, 
      author={Liyuan Liu and Haoming Jiang and Pengcheng He and Weizhu Chen and Xiaodong Liu and Jianfeng Gao and Jiawei Han},
      year={2020},
      eprint={1908.03265},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{ginsburg2020stochastic,
      title={Stochastic Gradient Methods with Layer-wise Adaptive Moments for Training of Deep Networks}, 
      author={Boris Ginsburg and Patrice Castonguay and Oleksii Hrinchuk and Oleksii Kuchaiev and Vitaly Lavrukhin and Ryan Leary and Jason Li and Huyen Nguyen and Yang Zhang and Jonathan M. Cohen},
      year={2020},
      eprint={1905.11286},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{zhang2019lookahead,
      title={Lookahead Optimizer: k steps forward, 1 step back}, 
      author={Michael R. Zhang and James Lucas and Geoffrey Hinton and Jimmy Ba},
      year={2019},
      eprint={1907.08610},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@article{yao2020adahessian,
  title={ADAHESSIAN: An adaptive second order optimizer for machine learning},
  author={Yao, Zhewei and Gholami, Amir and Shen, Sheng and Keutzer, Kurt and Mahoney, Michael W},
  journal={arXiv preprint arXiv:2006.00719},
  year={2020}
}
@article{ma2020apollo,
  title={Apollo: An Adaptive Parameter-wise Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization},
  author={Ma, Xuezhe},
  journal={arXiv preprint arXiv:2009.13586},
  year={2020}
}

@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}


@article{bai2018proxquant,
  title={Proxquant: Quantized neural networks via proximal operators},
  author={Bai, Yu and Wang, Yu-Xiang and Liberty, Edo},
  journal={arXiv preprint arXiv:1810.00861},
  year={2018}
}

@article{friesen2017deep,
  title={Deep learning as a mixed convex-combinatorial optimization problem},
  author={Friesen, Abram L and Domingos, Pedro},
  journal={arXiv preprint arXiv:1710.11573},
  year={2017}
}

@inproceedings{lee2015difference,
  title={Difference target propagation},
  author={Lee, Dong-Hyun and Zhang, Saizheng and Fischer, Asja and Bengio, Yoshua},
  booktitle={Joint european conference on machine learning and knowledge discovery in databases},
  pages={498--515},
  year={2015},
  organization={Springer}
}



@article{gysel2018ristretto,
  title={Ristretto: A framework for empirical study of resource-efficient inference in convolutional neural networks},
  author={Gysel, Philipp and Pimentel, Jon and Motamedi, Mohammad and Ghiasi, Soheil},
  journal={IEEE transactions on neural networks and learning systems},
  volume={29},
  number={11},
  pages={5784--5789},
  year={2018},
  publisher={IEEE}
}

@inproceedings{zhou2018explicit,
  title={Explicit loss-error-aware quantization for low-bit deep neural networks},
  author={Zhou, Aojun and Yao, Anbang and Wang, Kuan and Chen, Yurong},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9426--9435},
  year={2018}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}


@article{fan2020training,
  title={Training with quantization noise for extreme model compression},
  author={Fan, Angela and Stock, Pierre and Graham, Benjamin and Grave, Edouard and Gribonval, R{\'e}mi and J{\'e}gou, Herv{\'e} and Joulin, Armand},
  journal={arXiv e-prints},
  pages={arXiv--2004},
  year={2020}
}

@inproceedings{leng2018extremely,
  title={Extremely low bit neural network: Squeeze the last bit out with admm},
  author={Leng, Cong and Dou, Zesheng and Li, Hao and Zhu, Shenghuo and Jin, Rong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{chen2019metaquant,
  title={Metaquant: Learning to quantize by learning to penetrate non-differentiable quantization},
  author={Chen, Shangyu and Wang, Wenya and Pan, Sinno},
  year={2019}
}

@article{alizadeh2020gradient,
  title={Gradient L1 Regularization for Quantization Robustness},
  author={Alizadeh, Milad and Behboodi, Arash and van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen and Welling, Max},
  journal={arXiv preprint arXiv:2002.07520},
  year={2020}
}

@inproceedings{meller2019same,
  title={Same, same but different: Recovering neural network quantization error through weight factorization},
  author={Meller, Eldad and Finkelstein, Alexander and Almog, Uri and Grobman, Mark},
  booktitle={International Conference on Machine Learning},
  pages={4486--4495},
  year={2019},
  organization={PMLR}
}
@article{fang2020near,
  title={Near-Lossless Post-Training Quantization of Deep Neural Networks via a Piecewise Linear Approximation},
  author={Fang, Jun and Shafiee, Ali and Abdel-Aziz, Hamzah and Thorsley, David and Georgiadis, Georgios and Hassoun, Joseph},
  journal={arXiv preprint arXiv:2002.00104},
  year={2020}
}
@article{zhao2019improving,
  title={Improving neural network quantization without retraining using outlier channel splitting},
  author={Zhao, Ritchie and Hu, Yuwei and Dotzel, Jordan and De Sa, Christopher and Zhang, Zhiru},
  journal={Proceedings of Machine Learning Research},
  year={2019}
}

@article{banner2018post,
  title={Post-training 4-bit quantization of convolution networks for rapid-deployment},
  author={Banner, Ron and Nahshan, Yury and Hoffer, Elad and Soudry, Daniel},
  journal={arXiv preprint arXiv:1810.05723},
  year={2018}
}
@inproceedings{choukroun2019low,
  title={Low-bit Quantization of Neural Networks for Efficient Inference.},
  author={Choukroun, Yoni and Kravchik, Eli and Yang, Fan and Kisilev, Pavel},
  booktitle={ICCV Workshops},
  pages={3009--3018},
  year={2019}
}

@inproceedings{nagel2019data,
  title={Data-free quantization through weight equalization and bias correction},
  author={Nagel, Markus and Baalen, Mart van and Blankevoort, Tijmen and Welling, Max},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1325--1334},
  year={2019}
}
@inproceedings{fang2020post,
  title={Post-training piecewise linear quantization for deep neural networks},
  author={Fang, Jun and Shafiee, Ali and Abdel-Aziz, Hamzah and Thorsley, David and Georgiadis, Georgios and Hassoun, Joseph H},
  booktitle={European Conference on Computer Vision},
  pages={69--86},
  year={2020},
  organization={Springer}
}

@article{lee2018quantization,
  title={Quantization for rapid deployment of deep neural networks},
  author={Lee, Jun Haeng and Ha, Sangwon and Choi, Saerom and Lee, Won-Jo and Lee, Seungwon},
  journal={arXiv preprint arXiv:1810.05488},
  year={2018}
}