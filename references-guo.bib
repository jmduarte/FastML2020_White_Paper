% Encoding: UTF-8
@article{chen2019deep,
  author={Chen, Jiasi and Ran, Xukan},
  journal={Proceedings of the IEEE}, 
  title={Deep Learning With Edge Computing: A Review}, 
  year={2019},
  volume={107},
  number={8},
  pages={1655-1674},
  doi={10.1109/JPROC.2019.2921977}
}

@InProceedings{nasir2020deep,
  author    = {Yasir Sinan Nasir and Dongning Guo},
  booktitle = {Proc.\ Asilomar Conf. Signals Systems Computers},
  title     = {Deep actor-critic learning for distributed power control in wireless mobile networks},
  year      = {2020},
  organization = {Pacific Grove, CA}
}

@article{nasir2019multi-agent,
abstract = {This work demonstrates the potential of deep reinforcement learning techniques for transmit power control in wireless networks. Existing techniques typically find near-optimal power allocations by solving a challenging optimization problem. Most of these algorithms are not scalable to large networks in real-world scenarios because of their computational complexity and instantaneous cross-cell channel state information (CSI) requirement. In this paper, a distributively executed dynamic power allocation scheme is developed based on model-free deep reinforcement learning. Each transmitter collects CSI and quality of service (QoS) information from several neighbors and adapts its own transmit power accordingly. The objective is to maximize a weighted sum-rate utility function, which can be particularized to achieve maximum sum-rate or proportionally fair scheduling. Both random variations and delays in the CSI are inherently addressed using deep Q -learning. For a typical network architecture, the proposed algorithm is shown to achieve near-optimal power allocation in real time based on delayed CSI measurements available to the agents. The proposed scheme is especially suitable for practical scenarios where the system model is inaccurate and CSI delay is non-negligible.},
author = {Nasir, Yasar Sinan and Guo, Dongning},
doi = {10.1109/JSAC.2019.2933973},
issn = {15580008},
journal = {IEEE J. Sel. Areas Commun.},
number = {10},
title = {{Multi-Agent Deep Reinforcement Learning for Dynamic Power Allocation in Wireless Networks}},
volume = {37},
year = {2019}
}

@article{sun2018learning,
abstract = {Numerical optimization has played a central role in addressing key signal processing (SP) problems. Highly effective methods have been developed for a large variety of SP applications such as communications, radar, filter design, and speech and image analytics, just to name a few. However, optimization algorithms often entail considerable complexity, which creates a serious gap between theoretical design/analysis and real-time processing. In this paper, we aim at providing a new learning-based perspective to address this challenging issue. The key idea is to treat the input and output of an SP algorithm as an unknown nonlinear mapping and use a deep neural network (DNN) to approximate it. If the nonlinear mapping can be learned accurately by a DNN of moderate size, then SP tasks can be performed effectively-since passing the input through a DNN only requires a small number of simple operations. In our paper, we first identify a class of optimization algorithms that can be accurately approximated by a fully connected DNN. Second, to demonstrate the effectiveness of the proposed approach, we apply it to approximate a popular interference management algorithm, namely, the WMMSE algorithm. Extensive experiments using both synthetically generated wireless channel data and real DSL channel data have been conducted. It is shown that, in practice, only a small network is sufficient to obtain high approximation accuracy, and DNNs can achieve orders of magnitude speedup in computational time compared to the state-of-the-art interference management algorithm.},
author = {Sun, Haoran and Chen, Xiangyi and Shi, Qingjiang and Hong, Mingyi and Fu, Xiao and Sidiropoulos, Nicholas D.},
doi = {10.1109/TSP.2018.2866382},
issn = {1053587X},
journal = {IEEE Trans. Signal Process.},
number = {20},
title = {Learning to Optimize: Training Deep Neural Networks for Interference Management},
volume = {66},
year = {2018}
}

@article{calabrese2018learning,
abstract = {In the fifth generation (5G) of mobile broadband systems, radio resource management (RRM) will reach unprecedented levels of complexity. To cope with the ever more sophisticated RRM functionalities and the growing variety of scenarios, while carrying out the prompt decisions required in 5G, this manuscript presents a lean RRM architecture that capitalizes on recent advances in the field of machine learning in combination with the large amount of data readily available in the network from measurements and system observations. The architecture consists of a learner (or a few), which learns RRM policies directly from the data gathered in the network using a single general-purpose learning framework, and a set of distributed actors, which execute RRM policies issued by the learner and repeatedly generate samples of experience. Thus, the complexity of RRM is shifted to the design of the learning framework, while the RRM algorithms derived from this framework are executed in a computationally efficient distributed manner at the radio access nodes. The potential of this approach is verified in a pair of pertinent scenarios, and future directions on applications of machine learning to RRM are discussed. Although we focus on a mobile broadband context, the concepts proposed hereafter extend to any radio access network technology where one can conceive the idea of a central learning unit gathering data from distributed actors.},
author = {Calabrese, Francesco Davide and Wang, Li and Ghadimi, Euhanna and Peters, Gunnar and Hanzo, Lajos and Soldati, Pablo},
doi = {10.1109/MCOM.2018.1701031},
issn = {15581896},
journal = {IEEE Commun. Mag.},
number = {9},
title = {{Learning Radio Resource Management in RANs: Framework, Opportunities, and Challenges}},
volume = {56},
year = {2018}
}




@article{Ahmed2019,
abstract = {The increased complexity and heterogeneity of emerging 5G and B5G wireless networks will require a paradigm shift from traditional resource allocation mechanisms. Deep learning (DL) is a powerful tool where a multi-layer neural network can be trained to model a resource management algorithm using network data.Therefore, resource allocation decisions can be obtained without intensive online computations which would be required otherwise for the solution of resource allocation problems. In this context, this article focuses on the application of DL to obtain solutions for the radio resource allocation problems in multi-cell networks. Starting with a brief overview of a DNN as a DL model, relevant DNN architectures and the data training procedure, we provide an overview of existing state-of-the-art applying DL in the context of radio resource allocation. A qualitative comparison is provided in terms of their objectives, inputs/outputs, learning and data training methods. Then, we present a supervised DL model to solve the sub-band and power allocation problem in a multi-cell network. Using the data generated by a genetic algorithm, we first train the model and then test the accuracy of the proposed model in predicting the resource allocation solutions. Simulation results show that the trained DL model is able to provide the desired optimal solution 86.3 percent of the time.},
author = {Ahmed, K. I. and Tabassum, H. and Hossain, E.},
doi = {10.1109/MNET.2019.1900029},
issn = {1558156X},
journal = {IEEE Netw.},
title = {{Deep Learning for Radio Resource Allocation in Multi-Cell Networks}},
year = {2019}
}

@article{Ye2018,
abstract = {The emerging vehicular networks are expected to make everyday vehicular operation safer, greener, and more efficient and pave the path to autonomous driving in the advent of the fifth-generation (5G) cellular system. Machine learning, as a major branch of artificial intelligence, has been recently applied to wireless networks to provide a data-driven approach to solve traditionally challenging problems. In this article, we review recent advances in applying machine learning in vehicular networks and attempt to bring more attention to this upcoming area.},
author = {Ye, Hao and Liang, Le and Li, Geoffrey Ye and Kim, Joonbeom and Lu, Lu and Wu, May},
doi = {10.1109/MVT.2018.2811185},
issn = {15566072},
journal = {IEEE Veh. Technol. Mag.},
number = {2},
title = {{Machine Learning for Vehicular Networks: Recent Advances and Application Examples}},
volume = {13},
year = {2018}
}

@article{ren2020scheduling,
abstract = {In cellular federated edge learning (FEEL), multiple edge devices holding local data jointly train a neural network by communicating learning updates with an access point without exchanging their data samples. With very limited communication resources, it is beneficial to schedule the most informative local learning updates. This paper focuses on FEEL with gradient averaging over participating devices in each round of communication. A novel scheduling policy is proposed to exploit both diversity in multiuser channels and diversity in the 'importance' of the edge devices' learning updates. First, a new probabilistic scheduling framework is developed to yield unbiased update aggregation in FEEL. The importance of a local learning update is measured by its gradient divergence. If one edge device is scheduled in each communication round, the scheduling policy is derived in closed form to achieve the optimal trade-off between channel quality and update importance. The probabilistic scheduling framework is then extended to allow scheduling multiple edge devices in each communication round. Numerical results obtained using popular models and learning datasets demonstrate that the proposed scheduling policy can achieve faster model convergence and higher learning accuracy than conventional scheduling policies that only exploit a single type of diversity.},
author = {Ren, Jinke and He, Yinghui and Wen, Dingzhu and Yu, Guanding and Huang, Kaibin and Guo, Dongning},
doi = {10.1109/TWC.2020.3015671},
issn = {15582248},
journal = {IEEE Trans. Wirel. Commun.},
number = {11},
title = {{Scheduling for Cellular Federated Edge Learning with Importance and Channel Awareness}},
volume = {19},
year = {2020}
}
@inproceedings{Wang2018,
abstract = {In this work, we promote a different tool of multi-armed bandits (MAB), called arm identification, to choose a suitable channel for Opportunistic Spectrum Access (OSA) with proven accuracy while satisfying stringent constraints on delay, energy consumption, and channel switches. Noting that finding the best channel may not always be the optimal choice, we deviate from the celebrated best arm identification framework and adopt good arm identification (GAI), which results in a channel that is »good enough», but requires much less time and energy consumption under the same accuracy requirement. Robustness issues such as delayed or missing feedback are also studied under the new framework. Performance of the proposed algorithm is studied analytically and further corroborated via numerical simulations.},
author = {Wang, Zhiyang and Ying, Ziyu and Shen, Cong},
booktitle = {2018 IEEE Glob. Conf. Signal Inf. Process. Glob. 2018 - Proc.},
doi = {10.1109/GlobalSIP.2018.8646686},
title = {{Opportunistic spectrum access VIA good ARM identification}},
year = {2018}
}

@Article{challita2018proactive,
  author    = {Ursula Challita and Li Dong and Walid Saad},
  journal   = {IEEE Transactions on Wireless Communications},
  title     = {Proactive Resource Management for {LTE} in Unlicensed Spectrum: A Deep Learning Perspective},
  year      = {2018},
  issn      = {1558-2248},
  pages     = {4674--4689},
  volume    = {17},
  abstract  = {Performing cellular long term evolution (LTE) communications in unlicensed spectrum using licensed assisted access LTE (LTE-LAA) is a promising approach to overcome wireless spectrum scarcity. However, to reap the benefits of LTE-LAA, a fair coexistence mechanism with other incumbent WiFi deployments is required. In this paper, a novel deep learning approach is proposed for modeling the resource allocation problem of LTE-LAA small base stations (SBSs). The proposed approach enables multiple SBSs to proactively perform dynamic channel selection, carrier aggregation, and fractional spectrum access while guaranteeing fairness with existing WiFi networks and other LTE-LAA operators. Adopting a proactive coexistence mechanism enables future delay-tolerant LTE-LAA data demands to be served within a given prediction window ahead of their actual arrival time thus avoiding the underutilization of the unlicensed spectrum during off-peak hours while maximizing the total served LTE-LAA traffic load. To this end, a noncooperative game model is formulated in which SBSs are modeled as homo egualis agents that aim at predicting a sequence of future actions and thus achieving long-term equal weighted fairness with wireless local area network and other LTE-LAA operators over a given time horizon. The proposed deep learning algorithm is then shown to reach a mixed-strategy Nash equilibrium, when it converges. Simulation results using real data traces show that the proposed scheme can yield up to 28% and 11% gains over a conventional reactive approach and a proportional fair coexistence mechanism, respectively. The results also show that the proposed framework prevents WiFi performance degradation for a densely deployed LTE-LAA network.},
  date      = {July 2018},
  doi       = {10.1109/TWC.2018.2829773},
  file      = {:Challita2018 - Proactive Resource Management for LTE in Unlicensed Spectrum_ a Deep Learning Perspective.pdf:PDF},
  issue     = {7},
  keywords  = {Resource management, Long Term Evolution, Wireless fidelity, Wireless communication, Machine learning, Games, Licensed assisted access LTE (LTE-LAA), LTE-U, small cell, unlicensed band, long short term memory (LSTM), deep reinforcement learning, game theory, proactive resource allocation},
  publisher = {IEEE},
}

@Article{huang2020deep,
  author    = {Hongji Huang and Song Guo and Guan Gui and Zhen Yang and Jianhua Zhang and Hikmet Sari and Fumiyuki Adachi},
  journal   = {IEEE Wireless Communications},
  title     = {Deep Learning for Physical-Layer {5G} Wireless Techniques: Opportunities, Challenges and Solutions},
  year      = {2020},
  issn      = {1558-0687},
  pages     = {214--222},
  volume    = {27},
  abstract  = {The new demands for high-reliability and ultra-high capacity wireless communication have led to extensive research into 5G communications. However, current communication systems, which were designed on the basis of conventional communication theories, significantly restrict further performance improvements and lead to severe limitations. Recently, the emerging deep learning techniques have been recognized as a promising tool for handling the complicated communication systems, and their potential for optimizing wireless communications has been demonstrated. In this article, we first review the development of deep learning solutions for 5G communication, and then propose efficient schemes for deep learning-based 5G scenarios. Specifically, the key ideas for several important deep learning-based communication methods are presented along with the research opportunities and challenges. In particular, novel communication frameworks of NOMA, massive multiple-input multiple-output (MIMO), and millimeter wave (mmWave) are investigated, and their superior performances are demonstrated. We envision that the appealing deep learning- based wireless physical layer frameworks will bring a new direction in communication theories and that this work will move us forward along this road.},
  date      = {February 2020},
  doi       = {10.1109/MWC.2019.1900027},
  file      = {:Huang2020 - Deep Learning for Physical Layer 5G Wireless Techniques_ Opportunities, Challenges and Solutions.pdf:PDF},
  issue     = {1},
  keywords  = {MIMO communication, Deep learning, 5G mobile communication, Channel estimation, Wireless communication, NOMA},
  publisher = {IEEE},
}

@Article{zhu2020toward,
  author  = {Zhu, Guangxu and Liu, Dongzhu and Du, Yuqing and You, Changsheng and Zhang, Jun and Huang, Kaibin},
  journal = {IEEE Communications Magazine},
  title   = {Toward an Intelligent Edge: Wireless Communication Meets Machine Learning},
  year    = {2020},
  number  = {1},
  pages   = {19-25},
  volume  = {58},
  doi     = {10.1109/MCOM.001.1900103},
}

@Article{liang2019towards,
  author  = {Liang, Fei and Shen, Cong and Yu, Wei and Wu, Feng},
  journal = {IEEE Transactions on Communications},
  title   = {Towards Optimal Power Control via Ensembling Deep Neural Networks},
  year    = {2020},
  number  = {3},
  pages   = {1760-1776},
  volume  = {68},
  doi     = {10.1109/TCOMM.2019.2957482},
}

@Article{zhao2019deep,
  author  = {Zhao, Nan and Liang, Ying-Chang and Niyato, Dusit and Pei, Yiyang and Wu, Minghu and Jiang, Yunhao},
  journal = {IEEE Transactions on Wireless Communications},
  title   = {Deep Reinforcement Learning for User Association and Resource Allocation in Heterogeneous Cellular Networks},
  year    = {2019},
  number  = {11},
  pages   = {5141-5152},
  volume  = {18},
  doi     = {10.1109/TWC.2019.2933417},
}

@Article{liang2019spectrum,
  author  = {Liang, Le and Ye, Hao and Li, Geoffrey Ye},
  journal = {IEEE Journal on Selected Areas in Communications},
  title   = {Spectrum Sharing in Vehicular Networks Based on Multi-Agent Reinforcement Learning},
  year    = {2019},
  number  = {10},
  pages   = {2282-2292},
  volume  = {37},
  doi     = {10.1109/JSAC.2019.2933962},
}

@Article{meng2020power,
  author  = {Meng, Fan and Chen, Peng and Wu, Lenan and Cheng, Julian},
  journal = {IEEE Transactions on Wireless Communications},
  title   = {Power Allocation in Multi-User Cellular Networks: Deep Reinforcement Learning Approaches},
  year    = {2020},
  number  = {10},
  pages   = {6255-6267},
  volume  = {19},
  doi     = {10.1109/TWC.2020.3001736},
}

@Article{zhang2019deep,
  author  = {Zhang, Ke and Zhu, Yongxu and Leng, Supeng and He, Yejun and Maharjan, Sabita and Zhang, Yan},
  journal = {IEEE Internet of Things Journal},
  title   = {Deep Learning Empowered Task Offloading for Mobile Edge Computing in Urban Informatics},
  year    = {2019},
  number  = {5},
  pages   = {7635-7647},
  volume  = {6},
  doi     = {10.1109/JIOT.2019.2903191},
}

@Article{wang2020convergence,
  author  = {Wang, Xiaofei and Han, Yiwen and Leung, Victor C. M. and Niyato, Dusit and Yan, Xueqiang and Chen, Xu},
  journal = {IEEE Communications Surveys Tutorials},
  title   = {Convergence of Edge Computing and Deep Learning: A Comprehensive Survey},
  year    = {2020},
  number  = {2},
  pages   = {869-904},
  volume  = {22},
  doi     = {10.1109/COMST.2020.2970550},
}

@Article{amiri2020federated,
  author  = {Amiri, Mohammad Mohammadi and Gündüz, Deniz},
  journal = {IEEE Transactions on Wireless Communications},
  title   = {Federated Learning Over Wireless Fading Channels},
  year    = {2020},
  number  = {5},
  pages   = {3546-3557},
  volume  = {19},
  doi     = {10.1109/TWC.2020.2974748},
}

@Article{niknam2020federated,
  author  = {Niknam, Solmaz and Dhillon, Harpreet S. and Reed, Jeffrey H.},
  journal = {IEEE Communications Magazine},
  title   = {Federated Learning for Wireless Communications: Motivation, Opportunities, and Challenges},
  year    = {2020},
  number  = {6},
  pages   = {46-51},
  volume  = {58},
  doi     = {10.1109/MCOM.001.1900461},
}

@Article{chen2021convergence,
  author  = {Chen, Mingzhe and Poor, H. Vincent and Saad, Walid and Cui, Shuguang},
  journal = {IEEE Transactions on Wireless Communications},
  title   = {Convergence Time Optimization for Federated Learning Over Wireless Networks},
  year    = {2021},
  number  = {4},
  pages   = {2457-2471},
  volume  = {20},
  doi     = {10.1109/TWC.2020.3042530},
}

@Comment{jabref-meta: databaseType:bibtex;}
